<<<<<<< HEAD
{"cells":[{"cell_type":"markdown","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["# **Feature Engineering**\n"]},{"cell_type":"markdown","metadata":{},"source":["Estimated time needed: **45** minutes\n"]},{"cell_type":"markdown","metadata":{},"source":["A critical part of the successful Machine Learning project is coming up with a good set of features to train on. This process is called feature engineering, and it involves three steps: feature transformation (transforming the original features), feature selection (selecting the most useful features to train on), and feature extraction (combining existing features to produce more useful ones). In this notebook we will explore different tools in Feature Engineering.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","metadata":{},"source":["After completing this lab you will be able to:\n"]},{"cell_type":"markdown","metadata":{},"source":["*   Understand the types of Feature Engineering\n","    *   Feature Transformation\n","        *   Dealing with Categorical Variables\n","            *   One Hot Encoding\n","            *   Label Encoding\n","        *   Date Time Transformations\n","    *   Feature Selection\n","    *   Feature Extraction using Principal Component Analysis\n"]},{"cell_type":"markdown","metadata":{},"source":["***\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Setup**\n"]},{"cell_type":"markdown","metadata":{},"source":["For this lab, we will be using the following libraries:\n","\n","*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for managing the data.\n","*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for mathematical operations.\n","*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for visualizing the data.\n","*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for visualizing the data.\n","*   [`plotly.express`](https://plotly.com/python/plotly-express/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for visualizing the data.\n","*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for machine learning and machine-learning-pipeline related functions.\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Installing Required Libraries**\n"]},{"cell_type":"markdown","metadata":{},"source":["The following required modules are pre-installed in the Skills Network Labs environment. However if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda) you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (3456979102.py, line 5)","output_type":"error","traceback":["\u001b[1;36m  Input \u001b[1;32mIn [5]\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install pandas\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"]}],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\"\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\"mamba\" no se reconoce como un comando interno o externo,\n","programa o archivo por lotes ejecutable.\n"]}],"source":["!mamba install -qy openpyxl"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Surpress warnings from using older version of sklearn:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["import skillsnetwork\n","import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","import plotly.express as px\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA"]},{"cell_type":"markdown","metadata":{},"source":["## **Reading and understanding our data**\n"]},{"cell_type":"markdown","metadata":{},"source":["For this lab, we will be using the airlines_data.xlsx file, hosted on IBM Cloud object. This dataset contains the prices of flight tickets for various airlines between the months of March and June of 2019 and between various cities. This dataset is often used for prediction analysis of the flight prices which are influenced by various factors, such as name of the airline, date of journey, route, departure and arrival times, the source and the destination of the trip, duration and other parameters.\n","\n","In this notebook, we will use the airlines dataset to perform feature engineering on some of its independent variables.\n"]},{"cell_type":"markdown","metadata":{},"source":["Let's start by reading the data into *pandas* data frame and looking at the first 5 rows using the `head()` method.\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b67128a3d6814488b26a747dc134b5c8","version_major":2,"version_minor":0},"text/plain":["Downloading airlines_data.xlsx:   0%|          | 0/530389 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Airline</th>\n","      <th>Date_of_Journey</th>\n","      <th>Source</th>\n","      <th>Destination</th>\n","      <th>Route</th>\n","      <th>Dep_Time</th>\n","      <th>Arrival_Time</th>\n","      <th>Duration</th>\n","      <th>Total_Stops</th>\n","      <th>Additional_Info</th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>IndiGo</td>\n","      <td>24/03/2019</td>\n","      <td>Banglore</td>\n","      <td>New Delhi</td>\n","      <td>BLR → DEL</td>\n","      <td>22:20</td>\n","      <td>01:10 22 Mar</td>\n","      <td>2h 50m</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>3897</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Air India</td>\n","      <td>1/05/2019</td>\n","      <td>Kolkata</td>\n","      <td>Banglore</td>\n","      <td>CCU → IXR → BBI → BLR</td>\n","      <td>05:50</td>\n","      <td>13:15</td>\n","      <td>7h 25m</td>\n","      <td>2 stops</td>\n","      <td>No info</td>\n","      <td>7662</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Jet Airways</td>\n","      <td>9/06/2019</td>\n","      <td>Delhi</td>\n","      <td>Cochin</td>\n","      <td>DEL → LKO → BOM → COK</td>\n","      <td>09:25</td>\n","      <td>04:25 10 Jun</td>\n","      <td>19h</td>\n","      <td>2 stops</td>\n","      <td>No info</td>\n","      <td>13882</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>IndiGo</td>\n","      <td>12/05/2019</td>\n","      <td>Kolkata</td>\n","      <td>Banglore</td>\n","      <td>CCU → NAG → BLR</td>\n","      <td>18:05</td>\n","      <td>23:30</td>\n","      <td>5h 25m</td>\n","      <td>1 stop</td>\n","      <td>No info</td>\n","      <td>6218</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>IndiGo</td>\n","      <td>01/03/2019</td>\n","      <td>Banglore</td>\n","      <td>New Delhi</td>\n","      <td>BLR → NAG → DEL</td>\n","      <td>16:50</td>\n","      <td>21:35</td>\n","      <td>4h 45m</td>\n","      <td>1 stop</td>\n","      <td>No info</td>\n","      <td>13302</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Airline Date_of_Journey    Source Destination                  Route  \\\n","0       IndiGo      24/03/2019  Banglore   New Delhi              BLR → DEL   \n","1    Air India       1/05/2019   Kolkata    Banglore  CCU → IXR → BBI → BLR   \n","2  Jet Airways       9/06/2019     Delhi      Cochin  DEL → LKO → BOM → COK   \n","3       IndiGo      12/05/2019   Kolkata    Banglore        CCU → NAG → BLR   \n","4       IndiGo      01/03/2019  Banglore   New Delhi        BLR → NAG → DEL   \n","\n","  Dep_Time  Arrival_Time Duration Total_Stops Additional_Info  Price  \n","0    22:20  01:10 22 Mar   2h 50m    non-stop         No info   3897  \n","1    05:50         13:15   7h 25m     2 stops         No info   7662  \n","2    09:25  04:25 10 Jun      19h     2 stops         No info  13882  \n","3    18:05         23:30   5h 25m      1 stop         No info   6218  \n","4    16:50         21:35   4h 45m      1 stop         No info  13302  "]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["URL = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0232EN-SkillsNetwork/asset/airlines_data.xlsx'\n","\n","await skillsnetwork.download_dataset(URL)\n","data = pd.read_excel('airlines_data.xlsx')\n","\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["By using the `info` function, we will take a look at the types of data that our dataset contains.\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10683 entries, 0 to 10682\n","Data columns (total 11 columns):\n"," #   Column           Non-Null Count  Dtype \n","---  ------           --------------  ----- \n"," 0   Airline          10683 non-null  object\n"," 1   Date_of_Journey  10683 non-null  object\n"," 2   Source           10683 non-null  object\n"," 3   Destination      10683 non-null  object\n"," 4   Route            10682 non-null  object\n"," 5   Dep_Time         10683 non-null  object\n"," 6   Arrival_Time     10683 non-null  object\n"," 7   Duration         10683 non-null  object\n"," 8   Total_Stops      10682 non-null  object\n"," 9   Additional_Info  10683 non-null  object\n"," 10  Price            10683 non-null  int64 \n","dtypes: int64(1), object(10)\n","memory usage: 918.2+ KB\n"]}],"source":["data.info()"]},{"cell_type":"markdown","metadata":{},"source":["As we see from the output above, we mostly have object data types, except for the 'price' column, which is an integer.\n"]},{"cell_type":"markdown","metadata":{},"source":["The `describe()` function provides the statistical information about the numerical variables. In our case, it is the 'price' variable.\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Price</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>10683.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>9087.064121</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>4611.359167</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1759.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>5277.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>8372.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>12373.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>79512.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              Price\n","count  10683.000000\n","mean    9087.064121\n","std     4611.359167\n","min     1759.000000\n","25%     5277.000000\n","50%     8372.000000\n","75%    12373.000000\n","max    79512.000000"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["data.describe()"]},{"cell_type":"markdown","metadata":{},"source":["Next, we will check for any null values.\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["Airline            0\n","Date_of_Journey    0\n","Source             0\n","Destination        0\n","Route              1\n","Dep_Time           0\n","Arrival_Time       0\n","Duration           0\n","Total_Stops        1\n","Additional_Info    0\n","Price              0\n","dtype: int64"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["data.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["Now that we have found some null points, we need to either remove them from our dataset or fill them with something else. In this case, we will use `fillna()` and `method='ffill'`, which fills the last observed non-null value forward until another non-null value is encountered.\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["data = data.fillna(method='ffill')"]},{"cell_type":"markdown","metadata":{},"source":["## **Feature Transformation**\n"]},{"cell_type":"markdown","metadata":{},"source":["Feature Transformation means transforming our features to the functions of the original features. For example, feature encoding, scaling, and discretization (the process of transforming continuous variables into discrete form, by creating bins or intervals) are the most common forms of data transformation.\n"]},{"cell_type":"markdown","metadata":{},"source":["### **Dealing with Categorical Variables**\n"]},{"cell_type":"markdown","metadata":{},"source":["Categorical variables represent qualitative data with no apparent inherent mathematical meaning. Therefore, for any machine learning analysis, all the categorical data must be transformed into the numerical data types. First, we'll start with 'Airlines' column, as it contains categorical values. We will use `unique()` method to obtain all the categories in this column.\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["['IndiGo',\n"," 'Air India',\n"," 'Jet Airways',\n"," 'SpiceJet',\n"," 'Multiple carriers',\n"," 'GoAir',\n"," 'Vistara',\n"," 'Air Asia',\n"," 'Vistara Premium economy',\n"," 'Jet Airways Business',\n"," 'Multiple carriers Premium economy',\n"," 'Trujet']"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["data['Airline'].unique().tolist()"]},{"cell_type":"markdown","metadata":{},"source":["From the above list, we notice that some of the airline names are being repeated. For example, 'Jet Airways' and 'Jet Airways Business'. This means that some of the airlines are subdivided into separate parts. We will combine these 'two-parts' airlines to make our categorical features more consistent with the rest of the variables.\n","\n","Here, we will use the *numpy* `where()` function to locate and combine the two categories.\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["data['Airline'] = np.where(data['Airline']=='Vistara Premium economy', 'Vistara', data['Airline'])\n","data['Airline'] = np.where(data['Airline']=='Jet Airways Business', 'Jet Airways', data['Airline'])"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 1\n","\n","In this exercise, use `np.where()` function to combine 'Multiple carriers Premium economy' and 'Multiple carriers' categories, like shown in the code above. Print the newly created list using `unique().tolist()` functions.\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["['IndiGo',\n"," 'Air India',\n"," 'Jet Airways',\n"," 'SpiceJet',\n"," 'Multiple carriers',\n"," 'GoAir',\n"," 'Vistara',\n"," 'Air Asia',\n"," 'Trujet']"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["# Enter your code and run the cell\n","data['Airline']=np.where(data['Airline']=='Multiple carriers Premium economy','Multiple carriers',data['Airline'])\n","data['Airline'].unique().tolist()"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","data\\['Airline'] = np.where(data\\['Airline']=='Multiple carriers Premium economy', 'Multiple carriers', data\\['Airline'])\n","data\\['Airline'].unique().tolist()\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **One Hot Encoding**\n"]},{"cell_type":"markdown","metadata":{},"source":["Now, to be recognized by a machine learning algorithms, our categorical variables should be converted into numerical ones. One way to do this is through *one hot encoding*. To learn more about this process, please visit this [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01).\n","\n","We will use, `get_dummies()` method to do this transformation. In the next cell, we will transform 'Airline', 'Source', and 'Destination' into their respective numeric variables. We will put all the transformed data into a 'data1' data frame.\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["data1 = pd.get_dummies(data=data, columns = ['Airline', 'Source', 'Destination'])"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date_of_Journey</th>\n","      <th>Route</th>\n","      <th>Dep_Time</th>\n","      <th>Arrival_Time</th>\n","      <th>Duration</th>\n","      <th>Total_Stops</th>\n","      <th>Additional_Info</th>\n","      <th>Price</th>\n","      <th>Airline_Air Asia</th>\n","      <th>Airline_Air India</th>\n","      <th>...</th>\n","      <th>Source_Chennai</th>\n","      <th>Source_Delhi</th>\n","      <th>Source_Kolkata</th>\n","      <th>Source_Mumbai</th>\n","      <th>Destination_Banglore</th>\n","      <th>Destination_Cochin</th>\n","      <th>Destination_Delhi</th>\n","      <th>Destination_Hyderabad</th>\n","      <th>Destination_Kolkata</th>\n","      <th>Destination_New Delhi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>24/03/2019</td>\n","      <td>BLR → DEL</td>\n","      <td>22:20</td>\n","      <td>01:10 22 Mar</td>\n","      <td>2h 50m</td>\n","      <td>non-stop</td>\n","      <td>No info</td>\n","      <td>3897</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1/05/2019</td>\n","      <td>CCU → IXR → BBI → BLR</td>\n","      <td>05:50</td>\n","      <td>13:15</td>\n","      <td>7h 25m</td>\n","      <td>2 stops</td>\n","      <td>No info</td>\n","      <td>7662</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9/06/2019</td>\n","      <td>DEL → LKO → BOM → COK</td>\n","      <td>09:25</td>\n","      <td>04:25 10 Jun</td>\n","      <td>19h</td>\n","      <td>2 stops</td>\n","      <td>No info</td>\n","      <td>13882</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12/05/2019</td>\n","      <td>CCU → NAG → BLR</td>\n","      <td>18:05</td>\n","      <td>23:30</td>\n","      <td>5h 25m</td>\n","      <td>1 stop</td>\n","      <td>No info</td>\n","      <td>6218</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01/03/2019</td>\n","      <td>BLR → NAG → DEL</td>\n","      <td>16:50</td>\n","      <td>21:35</td>\n","      <td>4h 45m</td>\n","      <td>1 stop</td>\n","      <td>No info</td>\n","      <td>13302</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 28 columns</p>\n","</div>"],"text/plain":["  Date_of_Journey                  Route Dep_Time  Arrival_Time Duration  \\\n","0      24/03/2019              BLR → DEL    22:20  01:10 22 Mar   2h 50m   \n","1       1/05/2019  CCU → IXR → BBI → BLR    05:50         13:15   7h 25m   \n","2       9/06/2019  DEL → LKO → BOM → COK    09:25  04:25 10 Jun      19h   \n","3      12/05/2019        CCU → NAG → BLR    18:05         23:30   5h 25m   \n","4      01/03/2019        BLR → NAG → DEL    16:50         21:35   4h 45m   \n","\n","  Total_Stops Additional_Info  Price  Airline_Air Asia  Airline_Air India  \\\n","0    non-stop         No info   3897                 0                  0   \n","1     2 stops         No info   7662                 0                  1   \n","2     2 stops         No info  13882                 0                  0   \n","3      1 stop         No info   6218                 0                  0   \n","4      1 stop         No info  13302                 0                  0   \n","\n","   ...  Source_Chennai  Source_Delhi  Source_Kolkata  Source_Mumbai  \\\n","0  ...               0             0               0              0   \n","1  ...               0             0               1              0   \n","2  ...               0             1               0              0   \n","3  ...               0             0               1              0   \n","4  ...               0             0               0              0   \n","\n","   Destination_Banglore  Destination_Cochin  Destination_Delhi  \\\n","0                     0                   0                  0   \n","1                     1                   0                  0   \n","2                     0                   1                  0   \n","3                     1                   0                  0   \n","4                     0                   0                  0   \n","\n","   Destination_Hyderabad  Destination_Kolkata  Destination_New Delhi  \n","0                      0                    0                      1  \n","1                      0                    0                      0  \n","2                      0                    0                      0  \n","3                      0                    0                      0  \n","4                      0                    0                      1  \n","\n","[5 rows x 28 columns]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["data1.head()"]},{"cell_type":"markdown","metadata":{},"source":["Below, we will compare our original data frame with the transformed one.\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["(10683, 11)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/plain":["(10683, 28)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["data1.shape"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, we went from 11 original features in our dataset to 38. This is because *Pandas* `get_dummies()` approach when applied to a column with different categories (e.g. different airlines) will produce a new column (variable) for each unique categorical value (for each unique airline). It will place a one in the column corresponding to the categorical value present for that observation.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 2\n","\n","In this exercise, use `value_counts()` to determine the values distribution of the 'Total_Stops' parameter.\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["1 stop      5625\n","non-stop    3492\n","2 stops     1520\n","3 stops       45\n","4 stops        1\n","Name: Total_Stops, dtype: int64"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["# Enter your code and run the cell\n","data['Total_Stops'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","data\\[\"Total_Stops\"].value_counts()\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Label Encoding**\n"]},{"cell_type":"markdown","metadata":{},"source":["Since 'Total_Stops' is originally a categorical data type, we also need to convert it into numerical one. For this, we can perform a label encoding, where values are manually assigned to the corresponding keys, like \"0\" to a \"non-stop\", using the `replace()` function.\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date_of_Journey</th>\n","      <th>Route</th>\n","      <th>Dep_Time</th>\n","      <th>Arrival_Time</th>\n","      <th>Duration</th>\n","      <th>Total_Stops</th>\n","      <th>Additional_Info</th>\n","      <th>Price</th>\n","      <th>Airline_Air Asia</th>\n","      <th>Airline_Air India</th>\n","      <th>...</th>\n","      <th>Source_Chennai</th>\n","      <th>Source_Delhi</th>\n","      <th>Source_Kolkata</th>\n","      <th>Source_Mumbai</th>\n","      <th>Destination_Banglore</th>\n","      <th>Destination_Cochin</th>\n","      <th>Destination_Delhi</th>\n","      <th>Destination_Hyderabad</th>\n","      <th>Destination_Kolkata</th>\n","      <th>Destination_New Delhi</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>24/03/2019</td>\n","      <td>BLR → DEL</td>\n","      <td>22:20</td>\n","      <td>01:10 22 Mar</td>\n","      <td>2h 50m</td>\n","      <td>0</td>\n","      <td>No info</td>\n","      <td>3897</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1/05/2019</td>\n","      <td>CCU → IXR → BBI → BLR</td>\n","      <td>05:50</td>\n","      <td>13:15</td>\n","      <td>7h 25m</td>\n","      <td>2</td>\n","      <td>No info</td>\n","      <td>7662</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9/06/2019</td>\n","      <td>DEL → LKO → BOM → COK</td>\n","      <td>09:25</td>\n","      <td>04:25 10 Jun</td>\n","      <td>19h</td>\n","      <td>2</td>\n","      <td>No info</td>\n","      <td>13882</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12/05/2019</td>\n","      <td>CCU → NAG → BLR</td>\n","      <td>18:05</td>\n","      <td>23:30</td>\n","      <td>5h 25m</td>\n","      <td>1</td>\n","      <td>No info</td>\n","      <td>6218</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01/03/2019</td>\n","      <td>BLR → NAG → DEL</td>\n","      <td>16:50</td>\n","      <td>21:35</td>\n","      <td>4h 45m</td>\n","      <td>1</td>\n","      <td>No info</td>\n","      <td>13302</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 28 columns</p>\n","</div>"],"text/plain":["  Date_of_Journey                  Route Dep_Time  Arrival_Time Duration  \\\n","0      24/03/2019              BLR → DEL    22:20  01:10 22 Mar   2h 50m   \n","1       1/05/2019  CCU → IXR → BBI → BLR    05:50         13:15   7h 25m   \n","2       9/06/2019  DEL → LKO → BOM → COK    09:25  04:25 10 Jun      19h   \n","3      12/05/2019        CCU → NAG → BLR    18:05         23:30   5h 25m   \n","4      01/03/2019        BLR → NAG → DEL    16:50         21:35   4h 45m   \n","\n","   Total_Stops Additional_Info  Price  Airline_Air Asia  Airline_Air India  \\\n","0            0         No info   3897                 0                  0   \n","1            2         No info   7662                 0                  1   \n","2            2         No info  13882                 0                  0   \n","3            1         No info   6218                 0                  0   \n","4            1         No info  13302                 0                  0   \n","\n","   ...  Source_Chennai  Source_Delhi  Source_Kolkata  Source_Mumbai  \\\n","0  ...               0             0               0              0   \n","1  ...               0             0               1              0   \n","2  ...               0             1               0              0   \n","3  ...               0             0               1              0   \n","4  ...               0             0               0              0   \n","\n","   Destination_Banglore  Destination_Cochin  Destination_Delhi  \\\n","0                     0                   0                  0   \n","1                     1                   0                  0   \n","2                     0                   1                  0   \n","3                     1                   0                  0   \n","4                     0                   0                  0   \n","\n","   Destination_Hyderabad  Destination_Kolkata  Destination_New Delhi  \n","0                      0                    0                      1  \n","1                      0                    0                      0  \n","2                      0                    0                      0  \n","3                      0                    0                      0  \n","4                      0                    0                      1  \n","\n","[5 rows x 28 columns]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["data1.replace({\"non-stop\":0,\"1 stop\":1,\"2 stops\":2,\"3 stops\":3,\"4 stops\":4},inplace=True)\n","data1.head()"]},{"cell_type":"markdown","metadata":{},"source":["### **Date Time Transformations**\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Transforming the 'Duration' time column**\n"]},{"cell_type":"markdown","metadata":{},"source":["Here, we will take a closer look at the 'Duration' variable. Duration is the time taken by a plane to reach its destination. It is the difference between the 'Dep_Time' and 'Arrival_Time'. In our dataset, the 'Duration' is expressed as a string, in hours and minutes. To be recognized by machine learning algorithms, we also need to transform it into numerical type.\n","\n","The code below will iterate through each record in 'Duration' column and split it into hours and minutes, as two additional separate columns. Also, we want to add the 'Duration_hours' (in minutes) to the 'Duration_minutes' column to obtain a 'Duration_Total_mins' time, in minutes. The total duration time column will be useful feature for any regression type of analysis.\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["duration = list(data1['Duration'])\n","for i in range(len(duration)) :\n","    if len(duration[i].split()) != 2:\n","        if 'h' in duration[i] :\n","            duration[i] = duration[i].strip() + ' 0m'\n","        elif 'm' in duration[i] :\n","            duration[i] = '0h {}'.format(duration[i].strip())\n","dur_hours = []\n","dur_minutes = []  \n"," \n","for i in range(len(duration)) :\n","    dur_hours.append(int(duration[i].split()[0][:-1]))\n","    dur_minutes.append(int(duration[i].split()[1][:-1]))\n","     \n"," \n","data1['Duration_hours'] = dur_hours\n","data1['Duration_minutes'] =dur_minutes\n","data1.loc[:,'Duration_hours'] *= 60\n","data1['Duration_Total_mins']= data1['Duration_hours']+data1['Duration_minutes']"]},{"cell_type":"markdown","metadata":{},"source":["Print 'data1' data frame to see the newly created columns.\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date_of_Journey</th>\n","      <th>Route</th>\n","      <th>Dep_Time</th>\n","      <th>Arrival_Time</th>\n","      <th>Duration</th>\n","      <th>Total_Stops</th>\n","      <th>Additional_Info</th>\n","      <th>Price</th>\n","      <th>Airline_Air Asia</th>\n","      <th>Airline_Air India</th>\n","      <th>...</th>\n","      <th>Source_Mumbai</th>\n","      <th>Destination_Banglore</th>\n","      <th>Destination_Cochin</th>\n","      <th>Destination_Delhi</th>\n","      <th>Destination_Hyderabad</th>\n","      <th>Destination_Kolkata</th>\n","      <th>Destination_New Delhi</th>\n","      <th>Duration_hours</th>\n","      <th>Duration_minutes</th>\n","      <th>Duration_Total_mins</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>24/03/2019</td>\n","      <td>BLR → DEL</td>\n","      <td>22:20</td>\n","      <td>01:10 22 Mar</td>\n","      <td>2h 50m</td>\n","      <td>0</td>\n","      <td>No info</td>\n","      <td>3897</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>120</td>\n","      <td>50</td>\n","      <td>170</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1/05/2019</td>\n","      <td>CCU → IXR → BBI → BLR</td>\n","      <td>05:50</td>\n","      <td>13:15</td>\n","      <td>7h 25m</td>\n","      <td>2</td>\n","      <td>No info</td>\n","      <td>7662</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>420</td>\n","      <td>25</td>\n","      <td>445</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9/06/2019</td>\n","      <td>DEL → LKO → BOM → COK</td>\n","      <td>09:25</td>\n","      <td>04:25 10 Jun</td>\n","      <td>19h</td>\n","      <td>2</td>\n","      <td>No info</td>\n","      <td>13882</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1140</td>\n","      <td>0</td>\n","      <td>1140</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12/05/2019</td>\n","      <td>CCU → NAG → BLR</td>\n","      <td>18:05</td>\n","      <td>23:30</td>\n","      <td>5h 25m</td>\n","      <td>1</td>\n","      <td>No info</td>\n","      <td>6218</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>300</td>\n","      <td>25</td>\n","      <td>325</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>01/03/2019</td>\n","      <td>BLR → NAG → DEL</td>\n","      <td>16:50</td>\n","      <td>21:35</td>\n","      <td>4h 45m</td>\n","      <td>1</td>\n","      <td>No info</td>\n","      <td>13302</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>240</td>\n","      <td>45</td>\n","      <td>285</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 31 columns</p>\n","</div>"],"text/plain":["  Date_of_Journey                  Route Dep_Time  Arrival_Time Duration  \\\n","0      24/03/2019              BLR → DEL    22:20  01:10 22 Mar   2h 50m   \n","1       1/05/2019  CCU → IXR → BBI → BLR    05:50         13:15   7h 25m   \n","2       9/06/2019  DEL → LKO → BOM → COK    09:25  04:25 10 Jun      19h   \n","3      12/05/2019        CCU → NAG → BLR    18:05         23:30   5h 25m   \n","4      01/03/2019        BLR → NAG → DEL    16:50         21:35   4h 45m   \n","\n","   Total_Stops Additional_Info  Price  Airline_Air Asia  Airline_Air India  \\\n","0            0         No info   3897                 0                  0   \n","1            2         No info   7662                 0                  1   \n","2            2         No info  13882                 0                  0   \n","3            1         No info   6218                 0                  0   \n","4            1         No info  13302                 0                  0   \n","\n","   ...  Source_Mumbai  Destination_Banglore  Destination_Cochin  \\\n","0  ...              0                     0                   0   \n","1  ...              0                     1                   0   \n","2  ...              0                     0                   1   \n","3  ...              0                     1                   0   \n","4  ...              0                     0                   0   \n","\n","   Destination_Delhi  Destination_Hyderabad  Destination_Kolkata  \\\n","0                  0                      0                    0   \n","1                  0                      0                    0   \n","2                  0                      0                    0   \n","3                  0                      0                    0   \n","4                  0                      0                    0   \n","\n","   Destination_New Delhi  Duration_hours  Duration_minutes  \\\n","0                      1             120                50   \n","1                      0             420                25   \n","2                      0            1140                 0   \n","3                      0             300                25   \n","4                      1             240                45   \n","\n","   Duration_Total_mins  \n","0                  170  \n","1                  445  \n","2                 1140  \n","3                  325  \n","4                  285  \n","\n","[5 rows x 31 columns]"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["data1.head()"]},{"cell_type":"markdown","metadata":{},"source":["As you have noticed, three new columns were created: 'Duration_hours', 'Duration_minutes', and 'Duration_Total_mins' - all numerical values.\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Transforming the 'Departure' and 'Arrival' Time Columns**\n"]},{"cell_type":"markdown","metadata":{},"source":["Now, we will transform the 'Dep_Time' and 'Arrival_Time' columns to the appropriate date and time format. We will use *pandas* `to_datetime()` function for this.\n","\n","We will split the 'Dep_Time' and 'Arrival_Time' columns into their corresponding hours and minutes columns.\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["data1[\"Dep_Hour\"]= pd.to_datetime(data1['Dep_Time']).dt.hour\n","data1[\"Dep_Min\"]= pd.to_datetime(data1['Dep_Time']).dt.minute"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 3\n","\n","Now, let's transform the 'Arrival_Time' column.\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# Enter your code and run the cell\n","data1[\"Arrival_Hour\"]= pd.to_datetime(data1['Arrival_Time']).dt.hour\n","data1[\"Arrival_Min\"]= pd.to_datetime(data1['Arrival_Time']).dt.minute"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","data1\\[\"Arrival_Hour\"]= pd.to_datetime(data1\\['Arrival_Time']).dt.hour\n","data1\\[\"Arrival_Min\"]= pd.to_datetime(data1\\['Arrival_Time']).dt.minute\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Splitting 'Departure/Arrival_Time' into Time Zones**\n"]},{"cell_type":"markdown","metadata":{},"source":["To further transform our 'Departure/Arrival_Time' column, we can break down the 24 hours format for the departure and arrival time into 4 different time zones: night, morning, afternoon, and evening. This might be an interesting feature engineering technique to see what time of a day has the most arrivals/departures.\n","\n","One way to do this is transformation is by using *pandas* `cut()` function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1['dep_timezone'] = pd.cut(data1.Dep_Hour, [0,6,12,18,24], labels=['Night','Morning','Afternoon','Evening'])\n","data1['dep_timezone'] "]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 4\n","\n","Now, let's transform the 'Arrival_Time' column into its corresponding time zones, as shown in the example above.\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# Enter your code and run the cell\n"," \n","\n","data1[\"Arrival_Hour\"]= pd.to_datetime(data1['Arrival_Time']).dt.hour\n","data1['arr_timezone'] = pd.cut(data1.Arrival_Hour, [0,6,12,18,24], labels=['Night','Morning','Afternoon','Evening'])"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","data1\\[\"Arrival_Hour\"]= pd.to_datetime(data1\\['Arrival_Time']).dt.hour\n","data1\\['arr_timezone'] = pd.cut(data1.Arrival_Hour, \\[0,6,12,18,24], labels=\\['Night','Morning','Afternoon','Evening'])\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Transforming the 'Date_of_Journey' Column**\n"]},{"cell_type":"markdown","metadata":{},"source":["Similar to the departure/arrival time, we will now extract some information from the 'date_of_journey' column, which is also an object type and can not be used for any machine learning algorithm yet.\n","\n","So, we will extract the month information first and store it under the 'Month' column name.\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["data1['Month']= pd.to_datetime(data1[\"Date_of_Journey\"], format=\"%d/%m/%Y\").dt.month"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 5\n","\n","Now, let's create 'Day' and 'Year' columns in a similar way.\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["# Enter your code and run the cell\n","data1['Day']= pd.to_datetime(data1[\"Date_of_Journey\"], format=\"%d/%m/%Y\").dt.day\n","data1['Year']= pd.to_datetime(data1[\"Date_of_Journey\"], format=\"%d/%m/%Y\").dt.year\n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","data1\\['Day']= pd.to_datetime(data1\\[\"Date_of_Journey\"], format=\"%d/%m/%Y\").dt.day\n","data1\\['Year']= pd.to_datetime(data1\\[\"Date_of_Journey\"], format=\"%d/%m/%Y\").dt.year\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["Additionally, we can extract the day of the weak name by using `dt.day_name()` function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1['day_of_week'] = pd.to_datetime(data1['Date_of_Journey']).dt.day_name()"]},{"cell_type":"markdown","metadata":{},"source":["## **Feature Selection**\n"]},{"cell_type":"markdown","metadata":{},"source":["Here, we will select only those attributes which best explain the relationship of the independent variables with respect to the target variable, 'price'. There are many methods for feature selection, building the heatmap and calculating the correlation coefficients scores are the most commonly used ones.\n","\n","First, we will select only the relevant and newly transformed variables (and exclude variables such as 'Route', 'Additional_Info', and all the original categorical variables), and place them into a 'new_data' data frame.\n"]},{"cell_type":"markdown","metadata":{},"source":["We will print all of our data1 columns.\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['Date_of_Journey', 'Route', 'Dep_Time', 'Arrival_Time', 'Duration',\n","       'Total_Stops', 'Additional_Info', 'Price', 'Airline_Air Asia',\n","       'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n","       'Airline_Jet Airways', 'Airline_Multiple carriers', 'Airline_SpiceJet',\n","       'Airline_Trujet', 'Airline_Vistara', 'Source_Banglore',\n","       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n","       'Destination_Banglore', 'Destination_Cochin', 'Destination_Delhi',\n","       'Destination_Hyderabad', 'Destination_Kolkata', 'Destination_New Delhi',\n","       'Duration_hours', 'Duration_minutes', 'Duration_Total_mins', 'Dep_Hour',\n","       'Dep_Min', 'Arrival_Hour', 'Arrival_Min', 'arr_timezone', 'Month',\n","       'Day', 'Year'],\n","      dtype='object')"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["data1.columns"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"\"['dep_timezone'] not in index\"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[1;32md:\\OneDrive - Universidad Peruana de Ciencias\\ESTUDIOS\\EspecializacionIBMMachineLearning\\CodigoFuente\\IBMMachineLearning\\01_DataCleaningAndExploratoryDataAnalysis\\Feature_Engineering_Lab.ipynb Cell 85'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000084?line=0'>1</a>\u001b[0m new_data \u001b[39m=\u001b[39m data1\u001b[39m.\u001b[39;49mloc[:,[\u001b[39m'\u001b[39;49m\u001b[39mTotal_Stops\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mAirline_Air Asia\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000084?line=1'>2</a>\u001b[0m        \u001b[39m'\u001b[39;49m\u001b[39mAirline_Air India\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mAirline_GoAir\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mAirline_IndiGo\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000084?line=2'>3</a>\u001b[0m        \u001b[39m'\u001b[39;49m\u001b[39mAirline_Jet Airways\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mAirline_Multiple carriers\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mAirline_SpiceJet\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000084?line=3'>4</a>\u001b[0m        \u001b[39m'\u001b[39;49m\u001b[39mAirline_Trujet\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mAirline_Vistara\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mSource_Banglore\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000084?line=4'>5</a>\u001b[0m        \u001b[39m'\u001b[39;49m\u001b[39mSource_Chennai\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mSource_Delhi\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mSource_Kolkata\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mSource_Mumbai\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000084?line=5'>6</a>\u001b[0m        \u001b[39m'\u001b[39;49m\u001b[39mDestination_Banglore\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mDestination_Cochin\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mDestination_Delhi\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000084?line=6'>7</a>\u001b[0m        \u001b[39m'\u001b[39;49m\u001b[39mDestination_Hyderabad\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mDestination_Kolkata\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mDestination_New Delhi\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000084?line=7'>8</a>\u001b[0m        \u001b[39m'\u001b[39;49m\u001b[39mDuration_hours\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mDuration_minutes\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mDuration_Total_mins\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mDep_Hour\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000084?line=8'>9</a>\u001b[0m        \u001b[39m'\u001b[39;49m\u001b[39mDep_Min\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdep_timezone\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mPrice\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m    960\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m    964\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1149\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1149\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:827\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    825\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 827\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    828\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1189\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1191\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1193\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1133\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m )\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1324\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1325\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1327\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1329\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m-> 5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[1;31mKeyError\u001b[0m: \"['dep_timezone'] not in index\""]}],"source":["new_data = data1.loc[:,['Total_Stops', 'Airline_Air Asia',\n","       'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n","       'Airline_Jet Airways', 'Airline_Multiple carriers', 'Airline_SpiceJet',\n","       'Airline_Trujet', 'Airline_Vistara', 'Source_Banglore',\n","       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n","       'Destination_Banglore', 'Destination_Cochin', 'Destination_Delhi',\n","       'Destination_Hyderabad', 'Destination_Kolkata', 'Destination_New Delhi',\n","       'Duration_hours', 'Duration_minutes', 'Duration_Total_mins', 'Dep_Hour',\n","       'Dep_Min', 'dep_timezone', 'Price']]"]},{"cell_type":"markdown","metadata":{},"source":["Now we will construct a `heatmap()`, using the *seaborn* library with a newly formed data frame, 'new_data'.\n"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'new_data' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32md:\\OneDrive - Universidad Peruana de Ciencias\\ESTUDIOS\\EspecializacionIBMMachineLearning\\CodigoFuente\\IBMMachineLearning\\01_DataCleaningAndExploratoryDataAnalysis\\Feature_Engineering_Lab.ipynb Cell 87'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000086?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m18\u001b[39m,\u001b[39m18\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000086?line=1'>2</a>\u001b[0m sns\u001b[39m.\u001b[39mheatmap(new_data\u001b[39m.\u001b[39mcorr(),annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRdYlGn\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000086?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n","\u001b[1;31mNameError\u001b[0m: name 'new_data' is not defined"]},{"data":{"text/plain":["<Figure size 1296x1296 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(figsize=(18,18))\n","sns.heatmap(new_data.corr(),annot=True,cmap='RdYlGn')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["From the heatmap above, extreme green means highly positively correlated features (relationship between two variables in which both variables move in the same direction), extreme red means negatively correlated features (relationship between two variables in which an increase in one variable is associated with a decrease in the other).\n"]},{"cell_type":"markdown","metadata":{},"source":["Now, we can use the `corr()` function to calculate and list the correlation between all independent variables and the 'price'.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features = new_data.corr()['Price'].sort_values()\n","features"]},{"cell_type":"markdown","metadata":{},"source":["We can also plot these correlation coefficients for easier visualization.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features.plot(kind='bar',figsize=(10,8))"]},{"cell_type":"markdown","metadata":{},"source":["From the graph above, we can deduct some of the highly correlated features and select only those ones for any future analysis.\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Feature Extraction using Principal Component Analysis (Optional)**\n"]},{"cell_type":"markdown","metadata":{},"source":["### **PCA with Scikit-Learn**\n"]},{"cell_type":"markdown","metadata":{},"source":["Dimentionality reduction is part of the feature extraction process that combines the existing features to produce more useful ones. The goal of dimensionality reduction is to simplify the data without loosing too much information. Principal Component Analysis (PCA) is one of the most popular dimensionality reduction algorithms. First, it identifies the hyperplane that lies closest to the data, and then it projects the data onto it. In this way, a few multidimensional features are merged into one.\n","\n","In the following portion of the lab, we will use `scikit-learn` library to perform some PCA on our data.\n","To learn more about `scikit-learn` PCA, please visit this [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01#sklearn.decomposition.PCA).\n"]},{"cell_type":"markdown","metadata":{},"source":["First, we must scale our data using the `StandardScaler()` function.\n","We will assign all the independent variables to x, and the dependent variable, 'price', to y.\n"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["x = data1.loc[:,['Total_Stops', 'Airline_Air Asia',\n","       'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n","       'Airline_Jet Airways', 'Airline_Multiple carriers', 'Airline_SpiceJet',\n","       'Airline_Trujet', 'Airline_Vistara', 'Source_Banglore',\n","       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n","       'Destination_Banglore', 'Destination_Cochin', 'Destination_Delhi',\n","       'Destination_Hyderabad', 'Destination_Kolkata', 'Destination_New Delhi',\n","       'Duration_hours', 'Duration_minutes', 'Duration_Total_mins', 'Dep_Hour',\n","       'Dep_Min']]"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["y= data1.Price"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"data":{"text/plain":["array([[-1.22052384, -0.17544122, -0.44291155, ..., -0.93158255,\n","         1.65425948, -0.23505036],\n","       [ 1.74150619, -0.17544122,  2.25778713, ..., -0.39007152,\n","        -1.30309491,  1.36349161],\n","       [ 1.74150619, -0.17544122, -0.44291155, ...,  0.97847452,\n","        -0.60724682,  0.0313733 ],\n","       ...,\n","       [-1.22052384, -0.17544122, -0.44291155, ..., -0.91189124,\n","        -0.78120884, -0.23505036],\n","       [-1.22052384, -0.17544122, -0.44291155, ..., -0.95127386,\n","        -0.25932278,  0.29779696],\n","       [ 1.74150619, -0.17544122,  2.25778713, ..., -0.28176932,\n","        -0.4332848 ,  1.62991527]])"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["scaler = StandardScaler()\n","x=scaler.fit_transform(x.astype(np.float64))\n","x"]},{"cell_type":"markdown","metadata":{},"source":["Once the data is scaled, we can apply the `fit_transform()` function to reduce the dimensionality of the dataset down to two dimensions.\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":["array([[-2.87558735, -0.55547298],\n","       [ 0.31882297,  2.39248356],\n","       [ 3.05931395, -0.52682949],\n","       ...,\n","       [-2.24754433, -0.5884857 ],\n","       [-2.69892748, -0.28828087],\n","       [ 1.92547817, -1.10424355]])"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["pca = PCA(n_components = 2)\n","pca.fit_transform(x)"]},{"cell_type":"markdown","metadata":{},"source":["### **Explained Variance Ratio**\n"]},{"cell_type":"markdown","metadata":{},"source":["Another useful piece of information in PCA is the explained variance ratio of each principal component, available via the `explained_variance_ratio_` function. The ratio indicates the proportion of the dataset's variance that lies along each principal component. Let's look at the explained variance ratio of each of our two components.\n"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"text/plain":["array([0.17545521, 0.12110718])"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["explained_variance=pca.explained_variance_ratio_\n","explained_variance"]},{"cell_type":"markdown","metadata":{},"source":["The first component constitutes 17.54% of the variance and second component constitutes 12.11% of the variance between the features.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 6 (Optional)\n","\n","In this exercise, experiment with the number of components to see how many dimensions our dataset could be reduced to in order to explain most of the variability between the features. Additionally, you can plot the components using bar plot to see how much variability each component represents.\n"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'PCA' object has no attribute 'explained_variance_ratio'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32md:\\OneDrive - Universidad Peruana de Ciencias\\ESTUDIOS\\EspecializacionIBMMachineLearning\\CodigoFuente\\IBMMachineLearning\\01_DataCleaningAndExploratoryDataAnalysis\\Feature_Engineering_Lab.ipynb Cell 108'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000107?line=1'>2</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components \u001b[39m=\u001b[39m \u001b[39m7\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000107?line=2'>3</a>\u001b[0m pca\u001b[39m.\u001b[39mfit_transform(x)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000107?line=3'>4</a>\u001b[0m explained_variance\u001b[39m=\u001b[39mpca\u001b[39m.\u001b[39;49mexplained_variance_ratio\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000107?line=4'>5</a>\u001b[0m explained_variance\n","\u001b[1;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'explained_variance_ratio'"]}],"source":["# Enter your code and run the cell\n","pca = PCA(n_components = 7)\n","pca.fit_transform(x)\n","explained_variance=pca.explained_variance_ratio\n","explained_variance\n"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (7,) and arg 1 with shape (2,).","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32md:\\OneDrive - Universidad Peruana de Ciencias\\ESTUDIOS\\EspecializacionIBMMachineLearning\\CodigoFuente\\IBMMachineLearning\\01_DataCleaningAndExploratoryDataAnalysis\\Feature_Engineering_Lab.ipynb Cell 109'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000108?line=0'>1</a>\u001b[0m \u001b[39m# Enter your code and run the cell\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000108?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m, \u001b[39m4\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000108?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39;49mbar(\u001b[39mrange\u001b[39;49m(\u001b[39m7\u001b[39;49m), explained_variance, alpha\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, align\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcenter\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000108?line=4'>5</a>\u001b[0m label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mindividual explained variance\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000108?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mExplained variance ratio\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/OneDrive%20-%20Universidad%20Peruana%20de%20Ciencias/ESTUDIOS/EspecializacionIBMMachineLearning/CodigoFuente/IBMMachineLearning/01_DataCleaningAndExploratoryDataAnalysis/Feature_Engineering_Lab.ipynb#ch0000108?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mPrincipal components\u001b[39m\u001b[39m'\u001b[39m)\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\pyplot.py:2399\u001b[0m, in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2395\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mbar)\n\u001b[0;32m   2396\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbar\u001b[39m(\n\u001b[0;32m   2397\u001b[0m         x, height, width\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m, bottom\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, align\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcenter\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   2398\u001b[0m         data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2399\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mbar(\n\u001b[0;32m   2400\u001b[0m         x, height, width\u001b[39m=\u001b[39mwidth, bottom\u001b[39m=\u001b[39mbottom, align\u001b[39m=\u001b[39malign,\n\u001b[0;32m   2401\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1414\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_axes.py:2342\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2339\u001b[0m     \u001b[39mif\u001b[39;00m yerr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2340\u001b[0m         yerr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_dx(yerr, y0, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_yunits)\n\u001b[1;32m-> 2342\u001b[0m x, height, width, y, linewidth, hatch \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mbroadcast_arrays(\n\u001b[0;32m   2343\u001b[0m     \u001b[39m# Make args iterable too.\u001b[39;49;00m\n\u001b[0;32m   2344\u001b[0m     np\u001b[39m.\u001b[39;49matleast_1d(x), height, width, y, linewidth, hatch)\n\u001b[0;32m   2346\u001b[0m \u001b[39m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[0;32m   2347\u001b[0m \u001b[39mif\u001b[39;00m orientation \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m:\n","File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\stride_tricks.py:540\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(subok, *args)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[39m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[39m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[39m#                  order='C').itviews\u001b[39;00m\n\u001b[0;32m    538\u001b[0m args \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39marray(_m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, subok\u001b[39m=\u001b[39msubok) \u001b[39mfor\u001b[39;00m _m \u001b[39min\u001b[39;00m args]\n\u001b[1;32m--> 540\u001b[0m shape \u001b[39m=\u001b[39m _broadcast_shape(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    542\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(array\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m shape \u001b[39mfor\u001b[39;00m array \u001b[39min\u001b[39;00m args):\n\u001b[0;32m    543\u001b[0m     \u001b[39m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[0;32m    544\u001b[0m     \u001b[39mreturn\u001b[39;00m args\n","File \u001b[1;32mc:\\Users\\carlo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\stride_tricks.py:422\u001b[0m, in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39msupplied arrays against each other.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[39m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[39m# consistently\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m b \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mbroadcast(\u001b[39m*\u001b[39;49margs[:\u001b[39m32\u001b[39;49m])\n\u001b[0;32m    423\u001b[0m \u001b[39m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[39mfor\u001b[39;00m pos \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m32\u001b[39m, \u001b[39mlen\u001b[39m(args), \u001b[39m31\u001b[39m):\n\u001b[0;32m    425\u001b[0m     \u001b[39m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[39m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[39m# use broadcasting to avoid allocating the full array\u001b[39;00m\n","\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (7,) and arg 1 with shape (2,)."]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAANT0lEQVR4nO3cYYjkd33H8ffHO1NpjKb0VpC706T00njYQtIlTRFqirZc8uDugUXuIFgleGAbKVWEFEuU+MiGWhCu1ZOKVdAYfSALntwDjQTEC7chNXgXItvTeheFrDHNk6Ax7bcPZtKdrneZf3Zndy/7fb/gYP7/+e3Mlx97752d2ZlUFZKk7e8VWz2AJGlzGHxJasLgS1ITBl+SmjD4ktSEwZekJqYGP8lnkzyZ5PuXuD5JPplkKcmjSW6c/ZiSpPUa8gj/c8CBF7n+VmDf+N9R4F/WP5YkadamBr+qHgR+/iJLDgGfr5FTwNVJXj+rASVJs7FzBrexGzg/cXxhfO6nqxcmOcrotwCuvPLKP7z++utncPeS1MfDDz/8s6qaW8vXziL4g1XVceA4wPz8fC0uLm7m3UvSy16S/1zr187ir3SeAPZOHO8Zn5MkXUZmEfwF4F3jv9a5GXimqn7t6RxJ0taa+pROki8BtwC7klwAPgK8EqCqPgWcAG4DloBngfds1LCSpLWbGvyqOjLl+gL+emYTSZI2hO+0laQmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqYlBwU9yIMnjSZaS3HWR69+Q5IEkjyR5NMltsx9VkrQeU4OfZAdwDLgV2A8cSbJ/1bK/B+6vqhuAw8A/z3pQSdL6DHmEfxOwVFXnquo54D7g0Ko1BbxmfPm1wE9mN6IkaRaGBH83cH7i+ML43KSPArcnuQCcAN5/sRtKcjTJYpLF5eXlNYwrSVqrWb1oewT4XFXtAW4DvpDk1267qo5X1XxVzc/Nzc3oriVJQwwJ/hPA3onjPeNzk+4A7geoqu8CrwJ2zWJASdJsDAn+aWBfkmuTXMHoRdmFVWt+DLwNIMmbGAXf52wk6TIyNfhV9TxwJ3ASeIzRX+OcSXJPkoPjZR8E3pvke8CXgHdXVW3U0JKkl27nkEVVdYLRi7GT5+6euHwWeMtsR5MkzZLvtJWkJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNTEo+EkOJHk8yVKSuy6x5p1JziY5k+SLsx1TkrReO6ctSLIDOAb8GXABOJ1koarOTqzZB/wd8JaqejrJ6zZqYEnS2gx5hH8TsFRV56rqOeA+4NCqNe8FjlXV0wBV9eRsx5QkrdeQ4O8Gzk8cXxifm3QdcF2S7yQ5leTAxW4oydEki0kWl5eX1zaxJGlNZvWi7U5gH3ALcAT4TJKrVy+qquNVNV9V83NzczO6a0nSEEOC/wSwd+J4z/jcpAvAQlX9qqp+CPyA0Q8ASdJlYkjwTwP7klyb5ArgMLCwas3XGD26J8kuRk/xnJvdmJKk9Zoa/Kp6HrgTOAk8BtxfVWeS3JPk4HjZSeCpJGeBB4APVdVTGzW0JOmlS1VtyR3Pz8/X4uLilty3JL1cJXm4qubX8rW+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmBgU/yYEkjydZSnLXi6x7R5JKMj+7ESVJszA1+El2AMeAW4H9wJEk+y+y7irgb4CHZj2kJGn9hjzCvwlYqqpzVfUccB9w6CLrPgZ8HPjFDOeTJM3IkODvBs5PHF8Yn/s/SW4E9lbV11/shpIcTbKYZHF5efklDytJWrt1v2ib5BXAJ4APTltbVcerar6q5ufm5tZ715Kkl2BI8J8A9k4c7xmfe8FVwJuBbyf5EXAzsOALt5J0eRkS/NPAviTXJrkCOAwsvHBlVT1TVbuq6pqqugY4BRysqsUNmViStCZTg19VzwN3AieBx4D7q+pMknuSHNzoASVJs7FzyKKqOgGcWHXu7kusvWX9Y0mSZs132kpSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmhgU/CQHkjyeZCnJXRe5/gNJziZ5NMk3k7xx9qNKktZjavCT7ACOAbcC+4EjSfavWvYIMF9VfwB8FfiHWQ8qSVqfIY/wbwKWqupcVT0H3AccmlxQVQ9U1bPjw1PAntmOKUlaryHB3w2cnzi+MD53KXcA37jYFUmOJllMsri8vDx8SknSus30RdsktwPzwL0Xu76qjlfVfFXNz83NzfKuJUlT7Byw5glg78TxnvG5/yfJ24EPA2+tql/OZjxJ0qwMeYR/GtiX5NokVwCHgYXJBUluAD4NHKyqJ2c/piRpvaYGv6qeB+4ETgKPAfdX1Zkk9yQ5OF52L/Bq4CtJ/j3JwiVuTpK0RYY8pUNVnQBOrDp398Tlt894LknSjPlOW0lqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpoYFPwkB5I8nmQpyV0Xuf43knx5fP1DSa6Z+aSSpHWZGvwkO4BjwK3AfuBIkv2rlt0BPF1Vvwv8E/DxWQ8qSVqfIY/wbwKWqupcVT0H3AccWrXmEPBv48tfBd6WJLMbU5K0XjsHrNkNnJ84vgD80aXWVNXzSZ4Bfhv42eSiJEeBo+PDXyb5/lqG3oZ2sWqvGnMvVrgXK9yLFb+31i8cEvyZqarjwHGAJItVNb+Z93+5ci9WuBcr3IsV7sWKJItr/dohT+k8AeydON4zPnfRNUl2Aq8FnlrrUJKk2RsS/NPAviTXJrkCOAwsrFqzAPzl+PJfAN+qqprdmJKk9Zr6lM74Ofk7gZPADuCzVXUmyT3AYlUtAP8KfCHJEvBzRj8Upjm+jrm3G/dihXuxwr1Y4V6sWPNexAfiktSD77SVpCYMviQ1seHB92MZVgzYiw8kOZvk0STfTPLGrZhzM0zbi4l170hSSbbtn+QN2Ysk7xx/b5xJ8sXNnnGzDPg/8oYkDyR5ZPz/5LatmHOjJflskicv9V6ljHxyvE+PJrlx0A1X1Yb9Y/Qi738AvwNcAXwP2L9qzV8BnxpfPgx8eSNn2qp/A/fiT4HfHF9+X+e9GK+7CngQOAXMb/XcW/h9sQ94BPit8fHrtnruLdyL48D7xpf3Az/a6rk3aC/+BLgR+P4lrr8N+AYQ4GbgoSG3u9GP8P1YhhVT96KqHqiqZ8eHpxi952E7GvJ9AfAxRp/L9IvNHG6TDdmL9wLHquppgKp6cpNn3CxD9qKA14wvvxb4ySbOt2mq6kFGf/F4KYeAz9fIKeDqJK+fdrsbHfyLfSzD7kutqarngRc+lmG7GbIXk+5g9BN8O5q6F+NfUfdW1dc3c7AtMOT74jrguiTfSXIqyYFNm25zDdmLjwK3J7kAnADevzmjXXZeak+ATf5oBQ2T5HZgHnjrVs+yFZK8AvgE8O4tHuVysZPR0zq3MPqt78Ekv19V/7WVQ22RI8Dnquofk/wxo/f/vLmq/merB3s52OhH+H4sw4ohe0GStwMfBg5W1S83abbNNm0vrgLeDHw7yY8YPUe5sE1fuB3yfXEBWKiqX1XVD4EfMPoBsN0M2Ys7gPsBquq7wKsYfbBaN4N6stpGB9+PZVgxdS+S3AB8mlHst+vztDBlL6rqmaraVVXXVNU1jF7POFhVa/7QqMvYkP8jX2P06J4kuxg9xXNuE2fcLEP24sfA2wCSvIlR8Jc3dcrLwwLwrvFf69wMPFNVP532RRv6lE5t3McyvOwM3It7gVcDXxm/bv3jqjq4ZUNvkIF70cLAvTgJ/HmSs8B/Ax+qqm33W/DAvfgg8Jkkf8voBdx3b8cHiEm+xOiH/K7x6xUfAV4JUFWfYvT6xW3AEvAs8J5Bt7sN90qSdBG+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElq4n8BzPZculjwdYoAAAAASUVORK5CYII=","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Enter your code and run the cell\n","plt.figure(figsize=(6, 4))\n","\n","plt.bar(range(7), explained_variance, alpha=0.5, align='center', \n","label='individual explained variance')\n","plt.ylabel('Explained variance ratio')\n","plt.xlabel('Principal components')\n","plt.legend(loc='best')\n","plt.tight_layout() \n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution_part1</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","pca = PCA(n_components = 7)\n","pca.fit_transform(x)\n","explained_variance=pca.explained_variance_ratio\\_\n","explained_variance\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution_part2</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","with plt.style.context('dark_background'):\n","\n","```\n","plt.figure(figsize=(6, 4))\n","\n","plt.bar(range(7), explained_variance, alpha=0.5, align='center', \n","label='individual explained variance')\n","plt.ylabel('Explained variance ratio')\n","plt.xlabel('Principal components')\n","plt.legend(loc='best')\n","plt.tight_layout() \n","```\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["### **Choosing the Right Number of Dimensions**\n","\n","Instead of arbitrary choosing the number of dimensions to reduce down to, it is simpler to choose the number of dimensions that add up to a sufficiently large proportion of the variance, let's say 95%.\n","\n","The following code performs PCA without reducing dimensionality, then computes the minimum number of dimensions required to preserve 95% of the variance.\n"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["pca = PCA()\n","pca.fit(x)\n","cumsum = np.cumsum(pca.explained_variance_ratio_)\n","d = np.argmax(cumsum >=0.95) + 1"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/plain":["16"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["d"]},{"cell_type":"markdown","metadata":{},"source":["There are 16 components required to meet 95% variance. Therefore, we could set n_components = 16 and run PCA again. However, there is better way, instead of specifying the number of principal components you want to preserve, you can set n_components to be a float between 0.0 and 1.0, indicating the ratio of variance you wish to preserve.\n"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["pca = PCA(n_components=0.95)\n","x_reduced = pca.fit_transform(x)"]},{"cell_type":"markdown","metadata":{},"source":["There is also a graphical way to determine the number of principal components in your analysis. It is to plot the explained variance as a function of the number of dimensions. There will usually be an elbow in the curve, where the explained variance stops growing fast. That point is usually the optimal point for the number of principal components.\n"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"fillpattern":{"shape":""},"hovertemplate":"# Components=%{x}<br>Explained Variance=%{y}<extra></extra>","legendgroup":"","line":{"color":"#636efa"},"marker":{"symbol":"circle"},"mode":"lines","name":"","orientation":"v","showlegend":false,"stackgroup":"1","type":"scatter","x":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26],"xaxis":"x","y":[0.17545521174120177,0.2965623971493188,0.3892116003649026,0.47201270646096144,0.5394083576785748,0.5921648126724569,0.6403602569762592,0.685278791256747,0.7265107629479886,0.7660181396459806,0.8046295549519958,0.8430524006416429,0.8799747298931162,0.9137434106090392,0.9425889258840522,0.9694439366021582,0.9903089707530426,1,1,1,1,1,1,1,1,1],"yaxis":"y"}],"layout":{"legend":{"tracegroupgap":0},"margin":{"t":60},"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0,1],"title":{"text":"# Components"}},"yaxis":{"anchor":"x","domain":[0,1],"title":{"text":"Explained Variance"}}}}},"metadata":{},"output_type":"display_data"}],"source":["px.area(\n","    x=range(1, cumsum.shape[0] + 1),\n","    y=cumsum,\n","    labels={\"x\": \"# Components\", \"y\": \"Explained Variance\"}\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Congratulations! - You have completed the lab\n"]},{"cell_type":"markdown","metadata":{},"source":["## Author\n"]},{"cell_type":"markdown","metadata":{},"source":["[Svitlana Kramar](https://www.linkedin.com/in/svitlana-kramar/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","metadata":{},"source":["| Date (YYYY-MM-DD) | Version | Changed By | Change Description      |\n","| ----------------- | ------- | ---------- | ----------------------- |\n","| 2022-01-17        | 0.1     | Svitlana   | Modified multiple areas |\n"]},{"cell_type":"markdown","metadata":{},"source":["Copyright © 2020 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"9bd63d4d0e53dd854605697514204d0a3a6bfb81f118d4d4374019a86f3401eb"}}},"nbformat":4,"nbformat_minor":4}
=======
{"cells":[{"cell_type":"markdown","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["# **Feature Engineering**\n"]},{"cell_type":"markdown","metadata":{},"source":["Estimated time needed: **45** minutes\n"]},{"cell_type":"markdown","metadata":{},"source":["A critical part of the successful Machine Learning project is coming up with a good set of features to train on. This process is called feature engineering, and it involves three steps: feature transformation (transforming the original features), feature selection (selecting the most useful features to train on), and feature extraction (combining existing features to produce more useful ones). In this notebook we will explore different tools in Feature Engineering.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","metadata":{},"source":["After completing this lab you will be able to:\n"]},{"cell_type":"markdown","metadata":{},"source":["*   Understand the types of Feature Engineering\n","    *   Feature Transformation\n","        *   Dealing with Categorical Variables\n","            *   One Hot Encoding\n","            *   Label Encoding\n","        *   Date Time Transformations\n","    *   Feature Selection\n","    *   Feature Extraction using Principal Component Analysis\n"]},{"cell_type":"markdown","metadata":{},"source":["***\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Setup**\n"]},{"cell_type":"markdown","metadata":{},"source":["For this lab, we will be using the following libraries:\n","\n","*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for managing the data.\n","*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for mathematical operations.\n","*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for visualizing the data.\n","*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for visualizing the data.\n","*   [`plotly.express`](https://plotly.com/python/plotly-express/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for visualizing the data.\n","*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01) for machine learning and machine-learning-pipeline related functions.\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Installing Required Libraries**\n"]},{"cell_type":"markdown","metadata":{},"source":["The following required modules are pre-installed in the Skills Network Labs environment. However if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda) you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!mamba install -qy openpyxl"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Surpress warnings from using older version of sklearn:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","import plotly.express as px\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA"]},{"cell_type":"markdown","metadata":{},"source":["## **Reading and understanding our data**\n"]},{"cell_type":"markdown","metadata":{},"source":["For this lab, we will be using the airlines_data.xlsx file, hosted on IBM Cloud object. This dataset contains the prices of flight tickets for various airlines between the months of March and June of 2019 and between various cities. This dataset is often used for prediction analysis of the flight prices which are influenced by various factors, such as name of the airline, date of journey, route, departure and arrival times, the source and the destination of the trip, duration and other parameters.\n","\n","In this notebook, we will use the airlines dataset to perform feature engineering on some of its independent variables.\n"]},{"cell_type":"markdown","metadata":{},"source":["Let's start by reading the data into *pandas* data frame and looking at the first 5 rows using the `head()` method.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = pd.read_excel('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0232EN-SkillsNetwork/asset/airlines_data.xlsx')\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["By using the `info` function, we will take a look at the types of data that our dataset contains.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.info()"]},{"cell_type":"markdown","metadata":{},"source":["As we see from the output above, we mostly have object data types, except for the 'price' column, which is an integer.\n"]},{"cell_type":"markdown","metadata":{},"source":["The `describe()` function provides the statistical information about the numerical variables. In our case, it is the 'price' variable.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.describe()"]},{"cell_type":"markdown","metadata":{},"source":["Next, we will check for any null values.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["Now that we have found some null points, we need to either remove them from our dataset or fill them with something else. In this case, we will use `fillna()` and `method='ffill'`, which fills the last observed non-null value forward until another non-null value is encountered.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = data.fillna(method='ffill')"]},{"cell_type":"markdown","metadata":{},"source":["## **Feature Transformation**\n"]},{"cell_type":"markdown","metadata":{},"source":["Feature Transformation means transforming our features to the functions of the original features. For example, feature encoding, scaling, and discretization (the process of transforming continuous variables into discrete form, by creating bins or intervals) are the most common forms of data transformation.\n"]},{"cell_type":"markdown","metadata":{},"source":["### **Dealing with Categorical Variables**\n"]},{"cell_type":"markdown","metadata":{},"source":["Categorical variables represent qualitative data with no apparent inherent mathematical meaning. Therefore, for any machine learning analysis, all the categorical data must be transformed into the numerical data types. First, we'll start with 'Airlines' column, as it contains categorical values. We will use `unique()` method to obtain all the categories in this column.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data['Airline'].unique().tolist()"]},{"cell_type":"markdown","metadata":{},"source":["From the above list, we notice that some of the airline names are being repeated. For example, 'Jet Airways' and 'Jet Airways Business'. This means that some of the airlines are subdivided into separate parts. We will combine these 'two-parts' airlines to make our categorical features more consistent with the rest of the variables.\n","\n","Here, we will use the *numpy* `where()` function to locate and combine the two categories.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data['Airline'] = np.where(data['Airline']=='Vistara Premium economy', 'Vistara', data['Airline'])\n","data['Airline'] = np.where(data['Airline']=='Jet Airways Business', 'Jet Airways', data['Airline'])"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 1\n","\n","In this exercise, use `np.where()` function to combine 'Multiple carriers Premium economy' and 'Multiple carriers' categories, like shown in the code above. Print the newly created list using `unique().tolist()` functions.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Enter your code and run the cell\n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","data\\['Airline'] = np.where(data\\['Airline']=='Multiple carriers Premium economy', 'Multiple carriers', data\\['Airline'])\n","data\\['Airline'].unique().tolist()\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **One Hot Encoding**\n"]},{"cell_type":"markdown","metadata":{},"source":["Now, to be recognized by a machine learning algorithms, our categorical variables should be converted into numerical ones. One way to do this is through *one hot encoding*. To learn more about this process, please visit this [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01).\n","\n","We will use, `get_dummies()` method to do this transformation. In the next cell, we will transform 'Airline', 'Source', and 'Destination' into their respective numeric variables. We will put all the transformed data into a 'data1' data frame.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1 = pd.get_dummies(data=data, columns = ['Airline', 'Source', 'Destination'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1.head()"]},{"cell_type":"markdown","metadata":{},"source":["Below, we will compare our original data frame with the transformed one.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1.shape"]},{"cell_type":"markdown","metadata":{},"source":["As we can see, we went from 11 original features in our dataset to 38. This is because *Pandas* `get_dummies()` approach when applied to a column with different categories (e.g. different airlines) will produce a new column (variable) for each unique categorical value (for each unique airline). It will place a one in the column corresponding to the categorical value present for that observation.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 2\n","\n","In this exercise, use `value_counts()` to determine the values distribution of the 'Total_Stops' parameter.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Enter your code and run the cell\n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","data\\[\"Total_Stops\"].value_counts()\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Label Encoding**\n"]},{"cell_type":"markdown","metadata":{},"source":["Since 'Total_Stops' is originally a categorical data type, we also need to convert it into numerical one. For this, we can perform a label encoding, where values are manually assigned to the corresponding keys, like \"0\" to a \"non-stop\", using the `replace()` function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1.replace({\"non-stop\":0,\"1 stop\":1,\"2 stops\":2,\"3 stops\":3,\"4 stops\":4},inplace=True)\n","data1.head()"]},{"cell_type":"markdown","metadata":{},"source":["### **Date Time Transformations**\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Transforming the 'Duration' time column**\n"]},{"cell_type":"markdown","metadata":{},"source":["Here, we will take a closer look at the 'Duration' variable. Duration is the time taken by a plane to reach its destination. It is the difference between the 'Dep_Time' and 'Arrival_Time'. In our dataset, the 'Duration' is expressed as a string, in hours and minutes. To be recognized by machine learning algorithms, we also need to transform it into numerical type.\n","\n","The code below will iterate through each record in 'Duration' column and split it into hours and minutes, as two additional separate columns. Also, we want to add the 'Duration_hours' (in minutes) to the 'Duration_minutes' column to obtain a 'Duration_Total_mins' time, in minutes. The total duration time column will be useful feature for any regression type of analysis.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["duration = list(data1['Duration'])\n","for i in range(len(duration)) :\n","    if len(duration[i].split()) != 2:\n","        if 'h' in duration[i] :\n","            duration[i] = duration[i].strip() + ' 0m'\n","        elif 'm' in duration[i] :\n","            duration[i] = '0h {}'.format(duration[i].strip())\n","dur_hours = []\n","dur_minutes = []  \n"," \n","for i in range(len(duration)) :\n","    dur_hours.append(int(duration[i].split()[0][:-1]))\n","    dur_minutes.append(int(duration[i].split()[1][:-1]))\n","     \n"," \n","data1['Duration_hours'] = dur_hours\n","data1['Duration_minutes'] =dur_minutes\n","data1.loc[:,'Duration_hours'] *= 60\n","data1['Duration_Total_mins']= data1['Duration_hours']+data1['Duration_minutes']"]},{"cell_type":"markdown","metadata":{},"source":["Print 'data1' data frame to see the newly created columns.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1.head()"]},{"cell_type":"markdown","metadata":{},"source":["As you have noticed, three new columns were created: 'Duration_hours', 'Duration_minutes', and 'Duration_Total_mins' - all numerical values.\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Transforming the 'Departure' and 'Arrival' Time Columns**\n"]},{"cell_type":"markdown","metadata":{},"source":["Now, we will transform the 'Dep_Time' and 'Arrival_Time' columns to the appropriate date and time format. We will use *pandas* `to_datetime()` function for this.\n","\n","We will split the 'Dep_Time' and 'Arrival_Time' columns into their corresponding hours and minutes columns.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1[\"Dep_Hour\"]= pd.to_datetime(data1['Dep_Time']).dt.hour\n","data1[\"Dep_Min\"]= pd.to_datetime(data1['Dep_Time']).dt.minute"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 3\n","\n","Now, let's transform the 'Arrival_Time' column.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Enter your code and run the cell\n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","data1\\[\"Arrival_Hour\"]= pd.to_datetime(data1\\['Arrival_Time']).dt.hour\n","data1\\[\"Arrival_Min\"]= pd.to_datetime(data1\\['Arrival_Time']).dt.minute\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Splitting 'Departure/Arrival_Time' into Time Zones**\n"]},{"cell_type":"markdown","metadata":{},"source":["To further transform our 'Departure/Arrival_Time' column, we can break down the 24 hours format for the departure and arrival time into 4 different time zones: night, morning, afternoon, and evening. This might be an interesting feature engineering technique to see what time of a day has the most arrivals/departures.\n","\n","One way to do this is transformation is by using *pandas* `cut()` function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1['dep_timezone'] = pd.cut(data1.Dep_Hour, [0,6,12,18,24], labels=['Night','Morning','Afternoon','Evening'])\n","data1['dep_timezone'] "]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 4\n","\n","Now, let's transform the 'Arrival_Time' column into its corresponding time zones, as shown in the example above.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Enter your code and run the cell\n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","data1\\[\"Arrival_Hour\"]= pd.to_datetime(data1\\['Arrival_Time']).dt.hour\n","data1\\['arr_timezone'] = pd.cut(data1.Arrival_Hour, \\[0,6,12,18,24], labels=\\['Night','Morning','Afternoon','Evening'])\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### **Transforming the 'Date_of_Journey' Column**\n"]},{"cell_type":"markdown","metadata":{},"source":["Similar to the departure/arrival time, we will now extract some information from the 'date_of_journey' column, which is also an object type and can not be used for any machine learning algorithm yet.\n","\n","So, we will extract the month information first and store it under the 'Month' column name.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1['Month']= pd.to_datetime(data1[\"Date_of_Journey\"], format=\"%d/%m/%Y\").dt.month"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 5\n","\n","Now, let's create 'Day' and 'Year' columns in a similar way.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Enter your code and run the cell\n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","data1\\['Day']= pd.to_datetime(data1\\[\"Date_of_Journey\"], format=\"%d/%m/%Y\").dt.day\n","data1\\['Year']= pd.to_datetime(data1\\[\"Date_of_Journey\"], format=\"%d/%m/%Y\").dt.year\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["Additionally, we can extract the day of the weak name by using `dt.day_name()` function.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1['day_of_week'] = pd.to_datetime(data1['Date_of_Journey']).dt.day_name()"]},{"cell_type":"markdown","metadata":{},"source":["## **Feature Selection**\n"]},{"cell_type":"markdown","metadata":{},"source":["Here, we will select only those attributes which best explain the relationship of the independent variables with respect to the target variable, 'price'. There are many methods for feature selection, building the heatmap and calculating the correlation coefficients scores are the most commonly used ones.\n","\n","First, we will select only the relevant and newly transformed variables (and exclude variables such as 'Route', 'Additional_Info', and all the original categorical variables), and place them into a 'new_data' data frame.\n"]},{"cell_type":"markdown","metadata":{},"source":["We will print all of our data1 columns.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data1.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_data = data1.loc[:,['Total_Stops', 'Airline_Air Asia',\n","       'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n","       'Airline_Jet Airways', 'Airline_Multiple carriers', 'Airline_SpiceJet',\n","       'Airline_Trujet', 'Airline_Vistara', 'Source_Banglore',\n","       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n","       'Destination_Banglore', 'Destination_Cochin', 'Destination_Delhi',\n","       'Destination_Hyderabad', 'Destination_Kolkata', 'Destination_New Delhi',\n","       'Duration_hours', 'Duration_minutes', 'Duration_Total_mins', 'Dep_Hour',\n","       'Dep_Min', 'dep_timezone', 'Price']]"]},{"cell_type":"markdown","metadata":{},"source":["Now we will construct a `heatmap()`, using the *seaborn* library with a newly formed data frame, 'new_data'.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.figure(figsize=(18,18))\n","sns.heatmap(new_data.corr(),annot=True,cmap='RdYlGn')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["From the heatmap above, extreme green means highly positively correlated features (relationship between two variables in which both variables move in the same direction), extreme red means negatively correlated features (relationship between two variables in which an increase in one variable is associated with a decrease in the other).\n"]},{"cell_type":"markdown","metadata":{},"source":["Now, we can use the `corr()` function to calculate and list the correlation between all independent variables and the 'price'.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features = new_data.corr()['Price'].sort_values()\n","features"]},{"cell_type":"markdown","metadata":{},"source":["We can also plot these correlation coefficients for easier visualization.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["features.plot(kind='bar',figsize=(10,8))"]},{"cell_type":"markdown","metadata":{},"source":["From the graph above, we can deduct some of the highly correlated features and select only those ones for any future analysis.\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Feature Extraction using Principal Component Analysis (Optional)**\n"]},{"cell_type":"markdown","metadata":{},"source":["### **PCA with Scikit-Learn**\n"]},{"cell_type":"markdown","metadata":{},"source":["Dimentionality reduction is part of the feature extraction process that combines the existing features to produce more useful ones. The goal of dimensionality reduction is to simplify the data without loosing too much information. Principal Component Analysis (PCA) is one of the most popular dimensionality reduction algorithms. First, it identifies the hyperplane that lies closest to the data, and then it projects the data onto it. In this way, a few multidimensional features are merged into one.\n","\n","In the following portion of the lab, we will use `scikit-learn` library to perform some PCA on our data.\n","To learn more about `scikit-learn` PCA, please visit this [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01#sklearn.decomposition.PCA).\n"]},{"cell_type":"markdown","metadata":{},"source":["First, we must scale our data using the `StandardScaler()` function.\n","We will assign all the independent variables to x, and the dependent variable, 'price', to y.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x = data1.loc[:,['Total_Stops', 'Airline_Air Asia',\n","       'Airline_Air India', 'Airline_GoAir', 'Airline_IndiGo',\n","       'Airline_Jet Airways', 'Airline_Multiple carriers', 'Airline_SpiceJet',\n","       'Airline_Trujet', 'Airline_Vistara', 'Source_Banglore',\n","       'Source_Chennai', 'Source_Delhi', 'Source_Kolkata', 'Source_Mumbai',\n","       'Destination_Banglore', 'Destination_Cochin', 'Destination_Delhi',\n","       'Destination_Hyderabad', 'Destination_Kolkata', 'Destination_New Delhi',\n","       'Duration_hours', 'Duration_minutes', 'Duration_Total_mins', 'Dep_Hour',\n","       'Dep_Min']]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y= data1.Price"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scaler = StandardScaler()\n","x=scaler.fit_transform(x.astype(np.float64))\n","x"]},{"cell_type":"markdown","metadata":{},"source":["Once the data is scaled, we can apply the `fit_transform()` function to reduce the dimensionality of the dataset down to two dimensions.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pca = PCA(n_components = 2)\n","pca.fit_transform(x)"]},{"cell_type":"markdown","metadata":{},"source":["### **Explained Variance Ratio**\n"]},{"cell_type":"markdown","metadata":{},"source":["Another useful piece of information in PCA is the explained variance ratio of each principal component, available via the `explained_variance_ratio_` function. The ratio indicates the proportion of the dataset's variance that lies along each principal component. Let's look at the explained variance ratio of each of our two components.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["explained_variance=pca.explained_variance_ratio_\n","explained_variance"]},{"cell_type":"markdown","metadata":{},"source":["The first component constitutes 17.54% of the variance and second component constitutes 12.11% of the variance between the features.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 6 (Optional)\n","\n","In this exercise, experiment with the number of components to see how many dimensions our dataset could be reduced to in order to explain most of the variability between the features. Additionally, you can plot the components using bar plot to see how much variability each component represents.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Enter your code and run the cell\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Enter your code and run the cell\n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution_part1</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","pca = PCA(n_components = 7)\n","pca.fit_transform(x)\n","explained_variance=pca.explained_variance_ratio\\_\n","explained_variance\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["<details>\n","<summary><strong>Solution_part2</strong> (Click Here)</summary>\n","    &emsp; &emsp; <code>\n","\n","with plt.style.context('dark_background'):\n","\n","```\n","plt.figure(figsize=(6, 4))\n","\n","plt.bar(range(7), explained_variance, alpha=0.5, align='center', \n","label='individual explained variance')\n","plt.ylabel('Explained variance ratio')\n","plt.xlabel('Principal components')\n","plt.legend(loc='best')\n","plt.tight_layout() \n","```\n","\n","</code>\n","</details>\n"]},{"cell_type":"markdown","metadata":{},"source":["### **Choosing the Right Number of Dimensions**\n","\n","Instead of arbitrary choosing the number of dimensions to reduce down to, it is simpler to choose the number of dimensions that add up to a sufficiently large proportion of the variance, let's say 95%.\n","\n","The following code performs PCA without reducing dimensionality, then computes the minimum number of dimensions required to preserve 95% of the variance.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pca = PCA()\n","pca.fit(x)\n","cumsum = np.cumsum(pca.explained_variance_ratio_)\n","d = np.argmax(cumsum >=0.95) + 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["d"]},{"cell_type":"markdown","metadata":{},"source":["There are 16 components required to meet 95% variance. Therefore, we could set n_components = 16 and run PCA again. However, there is better way, instead of specifying the number of principal components you want to preserve, you can set n_components to be a float between 0.0 and 1.0, indicating the ratio of variance you wish to preserve.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pca = PCA(n_components=0.95)\n","x_reduced = pca.fit_transform(x)"]},{"cell_type":"markdown","metadata":{},"source":["There is also a graphical way to determine the number of principal components in your analysis. It is to plot the explained variance as a function of the number of dimensions. There will usually be an elbow in the curve, where the explained variance stops growing fast. That point is usually the optimal point for the number of principal components.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["px.area(\n","    x=range(1, cumsum.shape[0] + 1),\n","    y=cumsum,\n","    labels={\"x\": \"# Components\", \"y\": \"Explained Variance\"}\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Congratulations! - You have completed the lab\n"]},{"cell_type":"markdown","metadata":{},"source":["## Author\n"]},{"cell_type":"markdown","metadata":{},"source":["[Svitlana Kramar](https://www.linkedin.com/in/svitlana-kramar/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork30654641-2022-01-01)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","metadata":{},"source":["| Date (YYYY-MM-DD) | Version | Changed By | Change Description      |\n","| ----------------- | ------- | ---------- | ----------------------- |\n","| 2022-01-17        | 0.1     | Svitlana   | Modified multiple areas |\n"]},{"cell_type":"markdown","metadata":{},"source":["Copyright © 2020 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
>>>>>>> 9aebc4afea00a8367ee580d5dff16458701ece2f
