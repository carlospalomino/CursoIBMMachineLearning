{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from tensorflow.keras.models  import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('data/diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>5</td>\n",
       "      <td>128</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.144</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.933</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0.583</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "628               5                     128              80               0   \n",
       "757               0                     123              72               0   \n",
       "266               0                     138               0               0   \n",
       "232               1                      79              80              25   \n",
       "15                7                     100               0               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "628        0  34.6              0.144   45             0  \n",
       "757        0  36.3              0.258   52             1  \n",
       "266        0  36.3              0.933   25             1  \n",
       "232       37  25.4              0.583   22             0  \n",
       "15         0  30.0              0.484   32             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.823\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "    \n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5683 - accuracy: 0.6997 - val_loss: 0.5738 - val_accuracy: 0.6979\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.6997 - val_loss: 0.5735 - val_accuracy: 0.6979\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.6997 - val_loss: 0.5732 - val_accuracy: 0.6979\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.6997 - val_loss: 0.5729 - val_accuracy: 0.6979\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7014 - val_loss: 0.5726 - val_accuracy: 0.6979\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.6997 - val_loss: 0.5723 - val_accuracy: 0.7031\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7014 - val_loss: 0.5720 - val_accuracy: 0.7031\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5662 - accuracy: 0.7014 - val_loss: 0.5717 - val_accuracy: 0.7031\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7014 - val_loss: 0.5714 - val_accuracy: 0.7031\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7014 - val_loss: 0.5711 - val_accuracy: 0.7031\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5652 - accuracy: 0.7014 - val_loss: 0.5708 - val_accuracy: 0.7031\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7014 - val_loss: 0.5705 - val_accuracy: 0.7031\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 953us/step - loss: 0.5646 - accuracy: 0.7031 - val_loss: 0.5702 - val_accuracy: 0.7031\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7031 - val_loss: 0.5699 - val_accuracy: 0.7031\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5640 - accuracy: 0.7031 - val_loss: 0.5696 - val_accuracy: 0.7031\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5637 - accuracy: 0.7049 - val_loss: 0.5693 - val_accuracy: 0.6979\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.5634 - accuracy: 0.7049 - val_loss: 0.5690 - val_accuracy: 0.7031\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5631 - accuracy: 0.7049 - val_loss: 0.5687 - val_accuracy: 0.7031\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.5628 - accuracy: 0.7049 - val_loss: 0.5685 - val_accuracy: 0.7031\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.7049 - val_loss: 0.5682 - val_accuracy: 0.7031\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5623 - accuracy: 0.7049 - val_loss: 0.5679 - val_accuracy: 0.7031\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.7049 - val_loss: 0.5676 - val_accuracy: 0.7031\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.7066 - val_loss: 0.5673 - val_accuracy: 0.7031\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7083 - val_loss: 0.5670 - val_accuracy: 0.7031\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5610 - accuracy: 0.7066 - val_loss: 0.5667 - val_accuracy: 0.7083\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5608 - accuracy: 0.7083 - val_loss: 0.5664 - val_accuracy: 0.7083\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5605 - accuracy: 0.7083 - val_loss: 0.5662 - val_accuracy: 0.7083\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.7083 - val_loss: 0.5659 - val_accuracy: 0.7083\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5598 - accuracy: 0.7083 - val_loss: 0.5656 - val_accuracy: 0.7083\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.7118 - val_loss: 0.5653 - val_accuracy: 0.7083\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5592 - accuracy: 0.7118 - val_loss: 0.5650 - val_accuracy: 0.7083\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7135 - val_loss: 0.5648 - val_accuracy: 0.7083\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.5587 - accuracy: 0.7153 - val_loss: 0.5645 - val_accuracy: 0.7135\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5584 - accuracy: 0.7153 - val_loss: 0.5642 - val_accuracy: 0.7135\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5581 - accuracy: 0.7153 - val_loss: 0.5639 - val_accuracy: 0.7135\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.7135 - val_loss: 0.5636 - val_accuracy: 0.7135\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.7118 - val_loss: 0.5634 - val_accuracy: 0.7135\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.7135 - val_loss: 0.5631 - val_accuracy: 0.7135\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5569 - accuracy: 0.7135 - val_loss: 0.5628 - val_accuracy: 0.7135\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7135 - val_loss: 0.5625 - val_accuracy: 0.7135\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.7153 - val_loss: 0.5623 - val_accuracy: 0.7135\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 0.7153 - val_loss: 0.5620 - val_accuracy: 0.7135\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.7153 - val_loss: 0.5617 - val_accuracy: 0.7135\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.5555 - accuracy: 0.7153 - val_loss: 0.5614 - val_accuracy: 0.7135\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7153 - val_loss: 0.5612 - val_accuracy: 0.7135\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7170 - val_loss: 0.5609 - val_accuracy: 0.7135\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5546 - accuracy: 0.7118 - val_loss: 0.5606 - val_accuracy: 0.7135\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.7153 - val_loss: 0.5604 - val_accuracy: 0.7135\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.5541 - accuracy: 0.7135 - val_loss: 0.5601 - val_accuracy: 0.7135\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.7135 - val_loss: 0.5598 - val_accuracy: 0.7135\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7153 - val_loss: 0.5596 - val_accuracy: 0.7135\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7153 - val_loss: 0.5593 - val_accuracy: 0.7135\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5529 - accuracy: 0.7153 - val_loss: 0.5590 - val_accuracy: 0.7135\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7170 - val_loss: 0.5588 - val_accuracy: 0.7135\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7170 - val_loss: 0.5585 - val_accuracy: 0.7135\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7170 - val_loss: 0.5582 - val_accuracy: 0.7135\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.7170 - val_loss: 0.5580 - val_accuracy: 0.7135\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.7153 - val_loss: 0.5577 - val_accuracy: 0.7135\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7170 - val_loss: 0.5574 - val_accuracy: 0.7135\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7153 - val_loss: 0.5572 - val_accuracy: 0.7083\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5507 - accuracy: 0.7205 - val_loss: 0.5569 - val_accuracy: 0.7083\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.5505 - accuracy: 0.7170 - val_loss: 0.5567 - val_accuracy: 0.7083\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7205 - val_loss: 0.5564 - val_accuracy: 0.7083\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.5499 - accuracy: 0.7205 - val_loss: 0.5562 - val_accuracy: 0.7031\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5496 - accuracy: 0.7188 - val_loss: 0.5559 - val_accuracy: 0.7083\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5494 - accuracy: 0.7205 - val_loss: 0.5556 - val_accuracy: 0.7083\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.5491 - accuracy: 0.7205 - val_loss: 0.5554 - val_accuracy: 0.7083\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.7205 - val_loss: 0.5551 - val_accuracy: 0.7083\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.7205 - val_loss: 0.5549 - val_accuracy: 0.7083\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.5483 - accuracy: 0.7205 - val_loss: 0.5546 - val_accuracy: 0.7083\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7205 - val_loss: 0.5544 - val_accuracy: 0.7083\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5478 - accuracy: 0.7222 - val_loss: 0.5541 - val_accuracy: 0.7083\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.5475 - accuracy: 0.7222 - val_loss: 0.5539 - val_accuracy: 0.7083\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7222 - val_loss: 0.5536 - val_accuracy: 0.7083\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5469 - accuracy: 0.7222 - val_loss: 0.5534 - val_accuracy: 0.7083\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.5467 - accuracy: 0.7222 - val_loss: 0.5531 - val_accuracy: 0.7083\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5464 - accuracy: 0.7222 - val_loss: 0.5529 - val_accuracy: 0.7083\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.5461 - accuracy: 0.7222 - val_loss: 0.5526 - val_accuracy: 0.7083\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5459 - accuracy: 0.7222 - val_loss: 0.5524 - val_accuracy: 0.7083\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.5456 - accuracy: 0.7222 - val_loss: 0.5521 - val_accuracy: 0.7083\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5453 - accuracy: 0.7240 - val_loss: 0.5519 - val_accuracy: 0.7083\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.5451 - accuracy: 0.7240 - val_loss: 0.5516 - val_accuracy: 0.7083\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7240 - val_loss: 0.5514 - val_accuracy: 0.7083\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.7240 - val_loss: 0.5511 - val_accuracy: 0.7083\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.5443 - accuracy: 0.7240 - val_loss: 0.5509 - val_accuracy: 0.7135\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.5440 - accuracy: 0.7240 - val_loss: 0.5507 - val_accuracy: 0.7135\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.5438 - accuracy: 0.7240 - val_loss: 0.5504 - val_accuracy: 0.7135\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.7205 - val_loss: 0.5502 - val_accuracy: 0.7188\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.7205 - val_loss: 0.5499 - val_accuracy: 0.7292\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.5430 - accuracy: 0.7240 - val_loss: 0.5497 - val_accuracy: 0.7292\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.7274 - val_loss: 0.5495 - val_accuracy: 0.7292\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.5425 - accuracy: 0.7240 - val_loss: 0.5492 - val_accuracy: 0.7292\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5422 - accuracy: 0.7257 - val_loss: 0.5490 - val_accuracy: 0.7292\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5420 - accuracy: 0.7257 - val_loss: 0.5487 - val_accuracy: 0.7292\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.5417 - accuracy: 0.7257 - val_loss: 0.5485 - val_accuracy: 0.7292\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.7274 - val_loss: 0.5483 - val_accuracy: 0.7292\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7274 - val_loss: 0.5480 - val_accuracy: 0.7292\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5410 - accuracy: 0.7292 - val_loss: 0.5478 - val_accuracy: 0.7292\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.5407 - accuracy: 0.7292 - val_loss: 0.5476 - val_accuracy: 0.7292\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.5404 - accuracy: 0.7292 - val_loss: 0.5473 - val_accuracy: 0.7292\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7292 - val_loss: 0.5471 - val_accuracy: 0.7292\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7292 - val_loss: 0.5469 - val_accuracy: 0.7292\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.5397 - accuracy: 0.7292 - val_loss: 0.5466 - val_accuracy: 0.7292\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7309 - val_loss: 0.5464 - val_accuracy: 0.7292\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5392 - accuracy: 0.7309 - val_loss: 0.5462 - val_accuracy: 0.7292\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.7292 - val_loss: 0.5460 - val_accuracy: 0.7292\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.7292 - val_loss: 0.5457 - val_accuracy: 0.7292\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.7292 - val_loss: 0.5455 - val_accuracy: 0.7292\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.7292 - val_loss: 0.5453 - val_accuracy: 0.7292\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5380 - accuracy: 0.7292 - val_loss: 0.5450 - val_accuracy: 0.7292\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.5377 - accuracy: 0.7292 - val_loss: 0.5448 - val_accuracy: 0.7344\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.7292 - val_loss: 0.5446 - val_accuracy: 0.7344\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5372 - accuracy: 0.7292 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.5370 - accuracy: 0.7309 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 965us/step - loss: 0.5367 - accuracy: 0.7309 - val_loss: 0.5439 - val_accuracy: 0.7344\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.7309 - val_loss: 0.5437 - val_accuracy: 0.7344\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7326 - val_loss: 0.5435 - val_accuracy: 0.7344\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7326 - val_loss: 0.5433 - val_accuracy: 0.7344\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.7326 - val_loss: 0.5430 - val_accuracy: 0.7396\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7326 - val_loss: 0.5428 - val_accuracy: 0.7396\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7326 - val_loss: 0.5426 - val_accuracy: 0.7396\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5350 - accuracy: 0.7344 - val_loss: 0.5424 - val_accuracy: 0.7396\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.5348 - accuracy: 0.7361 - val_loss: 0.5422 - val_accuracy: 0.7396\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7378 - val_loss: 0.5420 - val_accuracy: 0.7396\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7361 - val_loss: 0.5417 - val_accuracy: 0.7396\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.5341 - accuracy: 0.7378 - val_loss: 0.5415 - val_accuracy: 0.7396\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.5339 - accuracy: 0.7378 - val_loss: 0.5413 - val_accuracy: 0.7396\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7378 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5334 - accuracy: 0.7378 - val_loss: 0.5409 - val_accuracy: 0.7344\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.5332 - accuracy: 0.7396 - val_loss: 0.5407 - val_accuracy: 0.7344\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.5329 - accuracy: 0.7378 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.7396 - val_loss: 0.5402 - val_accuracy: 0.7344\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.7396 - val_loss: 0.5400 - val_accuracy: 0.7344\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.7378 - val_loss: 0.5398 - val_accuracy: 0.7344\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5320 - accuracy: 0.7396 - val_loss: 0.5396 - val_accuracy: 0.7344\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.7396 - val_loss: 0.5394 - val_accuracy: 0.7344\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5315 - accuracy: 0.7378 - val_loss: 0.5392 - val_accuracy: 0.7344\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7378 - val_loss: 0.5390 - val_accuracy: 0.7344\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.7378 - val_loss: 0.5388 - val_accuracy: 0.7344\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.7378 - val_loss: 0.5386 - val_accuracy: 0.7344\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 0.7396 - val_loss: 0.5384 - val_accuracy: 0.7344\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.5304 - accuracy: 0.7396 - val_loss: 0.5382 - val_accuracy: 0.7344\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5302 - accuracy: 0.7413 - val_loss: 0.5380 - val_accuracy: 0.7396\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.5300 - accuracy: 0.7431 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7431 - val_loss: 0.5376 - val_accuracy: 0.7396\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.5295 - accuracy: 0.7465 - val_loss: 0.5374 - val_accuracy: 0.7396\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.7465 - val_loss: 0.5372 - val_accuracy: 0.7396\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.5290 - accuracy: 0.7465 - val_loss: 0.5370 - val_accuracy: 0.7396\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5288 - accuracy: 0.7465 - val_loss: 0.5368 - val_accuracy: 0.7396\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.7465 - val_loss: 0.5366 - val_accuracy: 0.7344\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.5284 - accuracy: 0.7465 - val_loss: 0.5364 - val_accuracy: 0.7344\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5282 - accuracy: 0.7465 - val_loss: 0.5362 - val_accuracy: 0.7292\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.7465 - val_loss: 0.5360 - val_accuracy: 0.7292\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.5277 - accuracy: 0.7483 - val_loss: 0.5358 - val_accuracy: 0.7292\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7483 - val_loss: 0.5356 - val_accuracy: 0.7344\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.7483 - val_loss: 0.5354 - val_accuracy: 0.7344\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 981us/step - loss: 0.5271 - accuracy: 0.7483 - val_loss: 0.5352 - val_accuracy: 0.7344\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.7465 - val_loss: 0.5350 - val_accuracy: 0.7344\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7483 - val_loss: 0.5348 - val_accuracy: 0.7344\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5264 - accuracy: 0.7483 - val_loss: 0.5346 - val_accuracy: 0.7344\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.7483 - val_loss: 0.5344 - val_accuracy: 0.7344\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.5260 - accuracy: 0.7483 - val_loss: 0.5342 - val_accuracy: 0.7344\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 0.7483 - val_loss: 0.5341 - val_accuracy: 0.7344\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 953us/step - loss: 0.5256 - accuracy: 0.7465 - val_loss: 0.5339 - val_accuracy: 0.7344\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.7483 - val_loss: 0.5337 - val_accuracy: 0.7344\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5252 - accuracy: 0.7483 - val_loss: 0.5335 - val_accuracy: 0.7344\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5249 - accuracy: 0.7483 - val_loss: 0.5333 - val_accuracy: 0.7344\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5247 - accuracy: 0.7483 - val_loss: 0.5331 - val_accuracy: 0.7344\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.5245 - accuracy: 0.7483 - val_loss: 0.5329 - val_accuracy: 0.7344\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.5243 - accuracy: 0.7500 - val_loss: 0.5327 - val_accuracy: 0.7344\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5241 - accuracy: 0.7500 - val_loss: 0.5326 - val_accuracy: 0.7344\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.5239 - accuracy: 0.7500 - val_loss: 0.5324 - val_accuracy: 0.7344\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.7500 - val_loss: 0.5322 - val_accuracy: 0.7344\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.5235 - accuracy: 0.7500 - val_loss: 0.5320 - val_accuracy: 0.7344\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7500 - val_loss: 0.5318 - val_accuracy: 0.7344\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.7517 - val_loss: 0.5316 - val_accuracy: 0.7344\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7517 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.5227 - accuracy: 0.7517 - val_loss: 0.5313 - val_accuracy: 0.7344\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7535 - val_loss: 0.5311 - val_accuracy: 0.7344\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5223 - accuracy: 0.7517 - val_loss: 0.5309 - val_accuracy: 0.7344\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.5220 - accuracy: 0.7535 - val_loss: 0.5307 - val_accuracy: 0.7396\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7517 - val_loss: 0.5306 - val_accuracy: 0.7396\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.5216 - accuracy: 0.7517 - val_loss: 0.5304 - val_accuracy: 0.7396\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7517 - val_loss: 0.5302 - val_accuracy: 0.7396\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.7517 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.5210 - accuracy: 0.7535 - val_loss: 0.5299 - val_accuracy: 0.7396\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7517 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5206 - accuracy: 0.7535 - val_loss: 0.5295 - val_accuracy: 0.7396\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7517 - val_loss: 0.5293 - val_accuracy: 0.7396\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.5202 - accuracy: 0.7517 - val_loss: 0.5292 - val_accuracy: 0.7396\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7517 - val_loss: 0.5290 - val_accuracy: 0.7396\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.5198 - accuracy: 0.7517 - val_loss: 0.5288 - val_accuracy: 0.7396\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7517 - val_loss: 0.5287 - val_accuracy: 0.7396\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.7517 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.7517 - val_loss: 0.5283 - val_accuracy: 0.7396\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7517 - val_loss: 0.5282 - val_accuracy: 0.7396\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.5189 - accuracy: 0.7517 - val_loss: 0.5280 - val_accuracy: 0.7396\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.5187 - accuracy: 0.7535 - val_loss: 0.5278 - val_accuracy: 0.7396\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7535 - val_loss: 0.5276 - val_accuracy: 0.7396\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.7535 - val_loss: 0.5275 - val_accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 447us/step\n"
     ]
    }
   ],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "#y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1=np.argmax(y_pred_prob_nn_1,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40424648],\n",
       "       [0.6488679 ],\n",
       "       [0.33584097],\n",
       "       [0.3891675 ],\n",
       "       [0.20555167],\n",
       "       [0.4231977 ],\n",
       "       [0.11756687],\n",
       "       [0.39210647],\n",
       "       [0.6775269 ],\n",
       "       [0.32997355]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.641\n",
      "roc-auc is 0.801\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x281b58970>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmLElEQVR4nO3de5QU9Zn/8ffDDJeNd5GsBDDg/qIbwx2EjBEFzcWgAt4SUSMjKkJWiZf1lriJh8iiWXc1ZlVAghqXn6yagHDQ9cKiZH+ShAEBQUURcR01BskRzTEIzDy/P6p6LJrpyzA93VU1n9c5c+iu7p76ds3w9DPP91tPmbsjIiLp1aHSAxARkbalQC8iknIK9CIiKadALyKScgr0IiIpV13pAWQ77LDDvHfv3pUehohIoqxateoDd+/W3GOxC/S9e/emrq6u0sMQEUkUM3sr12Mq3YiIpJwCvYhIyinQi4ikXOxq9CJSPrt27aK+vp4dO3ZUeihSpC5dutCzZ086duxY9GsU6EXasfr6eg444AB69+6NmVV6OFKAu7Nt2zbq6+vp06dP0a9T6UakHduxYwddu3ZVkE8IM6Nr164t/gssVYF+xQqYMSP4V0SKoyCfLPvy80pN6eb//T8YORIaGqCqCu6+GyZNqvSoREQqLzUZ/W9+A7t3g3vw7/e/D1OmKLsXibNt27YxcOBABg4cyOGHH06PHj2a7u/cuTPva+vq6pg6dWqL9te7d28++OCD1gw5kVIT6M8+G6ojf580NMDMmXDCCTB7duXGJSK5de3alTVr1rBmzRomT57MVVdd1XS/U6dO7N69O+drhw4dyl133VXG0SZXagJ9TU1QrslecbR7N1x+uTJ7kZJp48mw2tpaJk+ezPDhw7nuuuv4wx/+QE1NDYMGDeK4445j48aNADz33HOcdtppANx8881MnDiRkSNHcuSRR7boA2DLli2cdNJJ9O/fn5NPPpn//d//BeDRRx+lb9++DBgwgBNOOAGADRs2MGzYMAYOHEj//v15/fXXS/zu20ZqavQQ1OT79YNf/Qruuy/I6gF27YKbboJbbgk+EESkGVdeCWvW5H/O9u2wbh00NkKHDtC/Pxx0UO7nDxwId97Z4qHU19fzwgsvUFVVxUcffcRvf/tbqqurefbZZ/nhD3/Ir3/9671e8+qrr7Js2TI+/vhjjj76aKZMmVLUWvMrrriCCRMmMGHCBObOncvUqVNZuHAh06ZN46mnnqJHjx58+OGHAMycOZMf/OAHnH/++ezcuZOGTJCJudRk9Bk1NXDvvXDPPXuWcv77v2HECJVxRFpl+/YgyEPw7/btbbKbc845h6qqqnCX2znnnHPo27cvV111FRs2bGj2NaeeeiqdO3fmsMMO4/Of/zzvv/9+UftasWIF5513HgDf+973+J//+R8Avva1r1FbW8t9993XFNBramr453/+Z2677Tbeeust/uZv/qa1b7UsUpXRR2Wy+5tvhqefDrY1NMDkyVBXBxddpOxeZA/FZN4rVsDJJ8POndCpE8yb1yb/kfbbb7+m2//0T//EqFGjWLBgAVu2bGHkyJHNvqZz585Nt6uqqvLW94sxc+ZMfv/737NkyRKGDBnCqlWrOO+88xg+fDhLlixh9OjRzJo1i5NOOqlV+ymH1GX0UTU1QaCPZvbuQVlHk7Qi+6CmBpYuhZ/+NPi3DNnS9u3b6dGjBwAPPPBAyb//cccdx/z58wGYN28eI0aMAOCNN95g+PDhTJs2jW7duvH222+zefNmjjzySKZOncrYsWNZt25dycfTFlId6GHPSdroeQa7dwfZ/eTJmqgVaZGaGrjxxrL9SXzddddx4403MmjQoFZn6QD9+/enZ8+e9OzZk6uvvppf/OIX3H///fTv35+HHnqIn//85wBce+219OvXj759+3LccccxYMAAHnnkEfr27cvAgQNZv349F154YavHUw7m7pUewx6GDh3qbXHhkRUr9p6kzaiu1glW0j698sorfPnLX670MKSFmvu5mdkqdx/a3PNTn9FnRCdpm8vup0xRdi8i6dRuAn3GpEnw/PNw2WVBq4SMxkaYNUu1exFJn6ICvZmdYmYbzWyTmd3QzOO1ZrbVzNaEX5eE20dFtq0xsx1mNq7E76HFisnu1T5BRNKiYKA3syrgbuDbwDHAeDM7ppmn/qe7Dwy/5gC4+7LMNuAk4BPg6ZKNvpXyZfczZwZN0hTwRSTpisnohwGb3H2zu+8E5gNj92FfZwNPuvsn+/DaNpMvu9+5U/1yRCT5ign0PYC3I/frw23ZzjKzdWb2mJn1aubxc4GHm9uBmU0yszozq9u6dWsRQyq9aHbfufPe5Rx1wxSRpCrVZOxioLe79weeAR6MPmhm3YF+wFPNvdjdZ7v7UHcf2q1btxINqeUy2f2yZXuXc9QNU6T0Ro0axVNP7RkW7rzzTqZMmZLzNSNHjiSzBHv06NFNfWiibr75Zm6//fa8+164cCEvv/xy0/0f//jHPPvssy0YffOizdbiophA/w4QzdB7htuauPs2d/80vDsHGJL1Pb4DLHD3Xfs60HIqNFmr7F6kNMaPH990VmrG/PnzGT9+fFGvf+KJJzj44IP3ad/ZgX7atGl8/etf36fvFXfFBPqVwJfMrI+ZdSIowSyKPiHM2DPGAK9kfY/x5CjbxFmuyVpl99KelbJL8dlnn82SJUuaLjKyZcsW3n33XUaMGMGUKVMYOnQoX/nKV/jJT37S7OujFxKZPn06Rx11FMcff3xTK2OA++67j2OPPZYBAwZw1lln8cknn/DCCy+waNEirr32WgYOHMgbb7xBbW0tjz32GABLly5l0KBB9OvXj4kTJ/Lpp5827e8nP/kJgwcPpl+/frz66qtFv9eHH3646Uzb66+/HoCGhgZqa2vp27cv/fr144477gDgrrvu4phjjqF///6ce+65LTyqeyvY1Mzdd5vZ5QRllypgrrtvMLNpQJ27LwKmmtkYYDfwZ6A283oz603wF8HzrR5tIbNnw9atcNJJJTs9u6Ym+Bo0KOhrn7mKFXyW3b/4Ilx4oZqkSbJVokvxoYceyrBhw3jyyScZO3Ys8+fP5zvf+Q5mxvTp0zn00ENpaGjg5JNPZt26dfTv37/Z77Nq1Srmz5/PmjVr2L17N4MHD2bIkKCwcOaZZ3LppZcCcNNNN/HLX/6SK664gjFjxnDaaadx9tln7/G9duzYQW1tLUuXLuWoo47iwgsv5N577+XKK68E4LDDDmP16tXcc8893H777cyZMyf/QQPeffddrr/+elatWsUhhxzCN7/5TRYuXEivXr145513WL9+PUBTGerWW2/lzTffpHPnzs2WplqqqBq9uz/h7ke5+9+5+/Rw24/DII+73+juX3H3Ae4+yt1fjbx2i7v3cPfGVo82n/nzg9T7ppvaJNVWdi/SNl2Ko+WbaNnmkUceYfDgwQwaNIgNGzbsUWbJ9tvf/pYzzjiDz33ucxx44IGMGTOm6bH169czYsQI+vXrx7x583K2Oc7YuHEjffr04aijjgJgwoQJLF++vOnxM888E4AhQ4awZcuWot7jypUrGTlyJN26daO6uprzzz+f5cuXc+SRR7J582auuOIK/uu//osDDzwQCPrxnH/++fzHf/wH1dWtbzKcnjbFmzd/djtz1lOJU+3s7H5XZMZB2b0kXaW6FI8dO5arrrqK1atX88knnzBkyBDefPNNbr/9dlauXMkhhxxCbW0tO3bs2KfvX1tby8KFCxkwYAAPPPAAzz33XKvGm2mHXIpWyIcccghr167lqaeeYubMmTzyyCPMnTuXJUuWsHz5chYvXsz06dN56aWXWhXw09MCYdSoPfsRZ856asPsfvJkZffSvrRFl+L999+fUaNGMXHixKZs/qOPPmK//fbjoIMO4v333+fJJ5/M+z1OOOEEFi5cyF//+lc+/vhjFi9e3PTYxx9/TPfu3dm1axfz5s1r2n7AAQfw8ccf7/W9jj76aLZs2cKmTZsAeOihhzjxxBNb9R6HDRvG888/zwcffEBDQwMPP/wwJ554Ih988AGNjY2cddZZ3HLLLaxevZrGxkbefvttRo0axW233cb27dv5y1/+0qr9pyejz/QjLlMhXdm9tFeZ3/1SGj9+PGeccUZTCWfAgAEMGjSIv//7v6dXr1587Wtfy/v6wYMH893vfpcBAwbw+c9/nmOPPbbpsZ/+9KcMHz6cbt26MXz48Kbgfu6553LppZdy1113NU3CAnTp0oX777+fc845h927d3PssccyefLkFr2fpUuX0rNnz6b7jz76KLfeeiujRo3C3Tn11FMZO3Ysa9eu5aKLLqIxrIfNmDGDhoYGLrjgArZv3467M3Xq1H1eWZSRvjbFFehHrBbIklRqU5xMalNcgUXw2buM0rp7Eam09AX6jAosk1HtXkTiKL2BHmKR3eusWom7uJVvJb99+XmlO9BnVDC717p7ibMuXbqwbds2BfuEcHe2bdtGly5dWvS69E3GFjJ79t7LZCBIv59/vk2WyGR2GV0MBMEHwKWXamWOVM6uXbuor6/f5zXqUn5dunShZ8+edMyaEMw3Gdv+Aj3kXiYzahRMn94mUTfXLs2Cz5iJExXwRWTfta9VN8XItUxm2TIYMaJNaiq5avfuusCJiLSt9hnoMzKF9G9+87NtDQ3BspnLLmuTGdPsC5xEabJWRNpC+yzdZFuxIkins/tWdOrUpjWVTDln9uzPGkVl6EQrEWkJlW4KybRPKPNFYzPlnHvv3bNNDyi7F5HSUaDPqOBFYydNguXLdaKViLQNBfqoCl40Vm0URKStKNA3p4Knt6qNgoiUmgJ9PhU6vVXZvYiUkgJ9IcruRSThFOiLpexeRBJKgb4lKhh1ld2LyL5SoN8X+aLurFnB1ZPbINirBbKI7AsF+n2VK7t3hx07glNe24haIItISyjQt1Y0u8+c3uoeRNqLL26z9FrZvYgUS4G+FDJR95JLPou4jY0wd26bdcPMUHYvIoUo0JfShRdCly57pteZbpiXXqrsXkQqoqhAb2anmNlGM9tkZjc083itmW01szXh1yWRx44ws6fN7BUze9nMepdw/PFSUwNLl+6dXrvDnDkVz+5HjlTAF2mX3D3vF1AFvAEcCXQC1gLHZD2nFvj3HK9/DvhGeHt/4HP59jdkyBBPhVmz3Dt2dDdzD0J98GXmPmmS+wsvVGT34F5dHTwuIukB1HmOuFpMRj8M2OTum919JzAfGFvMh4iZHQNUu/sz4YfKX9z9k+I+ghIuV3qdmaht4+J5BZtxikjMFBPoewBvR+7Xh9uynWVm68zsMTPrFW47CvjQzH5jZi+a2b+YWVX2C81skpnVmVnd1q1bW/wmYqtQ8XzKlKB+38a1+wo04xSRGCnVZOxioLe79weeAR4Mt1cDI4B/BI4lKP/UZr/Y3We7+1B3H9qtW7cSDSlGcmX3jY3BCVZtXDzXZK1I+1ZMoH8H6BW53zPc1sTdt7n7p+HdOcCQ8HY9sCYs++wGFgKDWzXipMoXbct0dXAtxRRpn4oJ9CuBL5lZHzPrBJwLLIo+wcy6R+6OAV6JvPZgM8uk6ScBL7duyAlX4eJ5hatJIlIBBQN9mIlfDjxFEMAfcfcNZjbNzMaET5tqZhvMbC0wlbA84+4NBGWbpWb2EmDAfaV/GwkTg+J5oWqSsnuR9LBgVU58DB061Ovq6io9jPKaPRsuvzxIqaM/j6qq4ESrCy8MPhzKvHuzoIvDxIltunsRKQEzW+XuQ5t9TIE+JlasCBqh3XdfkNVHVVfD3XcHaXgFdl9VBddcAwcfHMwbK+iLxI8CfZLENLuHIMOvqmrzzxwR2Qf5Ar163cRNhZfG5No9BIFfyzFFkkeBPo4qvPA93+5ByzFFkkalm7iLQe3+uefgww/hjjtg1649Hy9TRUlEClCNPg0yxfMKRtoKf+aISB6q0adBDK4OrlYKIsmkQJ8kua5TC2WNtOp7L5IsCvRJFPPsvkyte0SkSAr0SRXD7L651j1Tpii7F6k0Bfqki1F231zrnsZGZfcilaZVN2kSg5U50WE01zvn9NPhC1/QckyRUtPyyvYk1xpIs6DEM3FixZdiQjCUiy9WwBcpFQX69ihXdg9lXfSer3dOmYcikmpaR98eRWv3nTvv+ViFJmuz54zLPBSRdksZfXuQqaPMnh3MjkaVMaXODOOPf4TFi3V2rUgpqXQjgdmz4R/+IUijoyrQsKbC3ZhFUkelGwlMmgTLlwflnA6RH30F2lHqQuUi5aNA395kFr3fe29QK4kqc8G8UO+cyZODDwLV7kVaR6Wb9iwmtfvoUHQpQ5F9oxq95JeA2j3oUoYi+ahGL/lFa/cVLpjrUoYipadAL4GYNElrbii5LmWodsgixVHpRvYWo0tJZV/KsLmSjtbfi6hGL/sqJk3SMjKfP/ffH/S81/p7kc+oRi/7JgYtkKPytUPW+nuR3JTRS3Filt1Hh9RcO+QxY6B7d2X40n60OqM3s1PMbKOZbTKzG5p5vNbMtprZmvDrkshjDZHti/b9bUhFxSy7jw4pO7t3h8cfD4Z14omasBUpmNGbWRXwGvANoB5YCYx395cjz6kFhrr75c28/i/uvn+xA1JGnwAJyu4zNGEradfajH4YsMndN7v7TmA+MLaUA5SEKZTdV2Ddo9ohi+RWTKDvAbwduV8fbst2lpmtM7PHzKxXZHsXM6szs9+Z2bjmdmBmk8Ln1G3durXowUsF5VvsvnNnRSdrM59B48bFpsokUlGlWnWzGOjt7v2BZ4AHI499Mfxz4jzgTjP7u+wXu/tsdx/q7kO7detWoiFJWURT6Qpe4CQqE/AXLMjdMG3KlODDQNm9tAfFBPp3gGiG3jPc1sTdt7n7p+HdOcCQyGPvhP9uBp4DBrVivBJH0XWPMZqshdwTto2NMGsWjBgB118PM2Yo6EuKuXveL6Aa2Az0AToBa4GvZD2ne+T2GcDvwtuHAJ3D24cBrwPH5NvfkCFDXBJu1iz3jh3dg3nRz76qqtwnT3Z/4YWKDsts76GZuVdXB88RSSKgznPE1YIZvbvvBi4HngJeAR5x9w1mNs3MxoRPm2pmG8xsLTAVqA23fxmoC7cvA271yGodSakYLsWMDksN06S90QlT0rZiuBQzOiwtx5S0UK8bqawYNUnLHla+hmlmcMklcNFFOrtW4k+BXuIhxlcEL/RZdOqpaqkg8aZAL/ER0+w+o1BJp2NHuPhiBXyJH3WvlPgodEXwKVMqOhuafVpA9kVPdu3SSVeSPAr0Uhn5FrhXOJJmt0NWSwVJOpVupPJy1Us6dAhq9xMmVLROkqk2/fGPsHhxLCtOIqrRSwLEvHafka8H/qmnQs+eqt9LZSjQS3Lki6QXXRSsd6xwFM33mQSasJXK0GSsJEe+q4nMnRs0p6nwLGi++WTQhK3EjzJ6ia98ax3PPz+IpNu2Bf3vK7z+/pe/3PvkX4jNNIO0AyrdSHIVqpOYBZl/hWv4hSZsq6rgmmvg4IMr+rkkKaZAL8lX6EymGJxdm6E+OlIJqtFL8mWfydQh61c3RpePytclE7QGX8pPGb0kT7Qb2b/9WxA5o5TdSzuk0o2kVwLW3xfTJfOCC+D44ys+tywJpkAv6RfTvvfZEjK3LAmkGr2kX0yvapWt0Bp8XelK2oIyekmfGPe9j8pk9/ffH/wh0ti493Oqq+Hqq7UsUwpT6UbanwTU7jMK1fBBJR0pTIFe2q98vXMuvRRqa2OVJheq4cfsjxKJEdXopf3K1ztn9uxY9M6JKlTDj9mUgySEMnppP/Itav/Wt6BPn1ilysUsyzztNOjRI1bDlgpR6UYkI6E9hhM6bCkjBXqRbAk9ZTWhw5YyUI1eJFu0dp+gi8IWM+zJk+H002M3dKkgZfQihXoMd+oEEyfGri5SaNigkk57ki+jx90LfgGnABuBTcANzTxeC2wF1oRfl2Q9fiBQD/x7oX0NGTLERSpm1iz3jh3dzdyD6shnX9XVweMxlG/YMR+6lAhQ5zniasGM3syqgNeAb4TBeiUw3t1fjjynFhjq7pfn+B4/B7oBf871nAxl9FJx0VNWd+6M9dm1UYWudmX22ZWu1DwtfVpbox8GbHL3ze6+E5gPjG3BzocAfws8XexrRCoqs5h92bK919/HeCF7ZtiZlj/jxu196sADDwRv6Uc/iuVbkDZSTKDvAbwduV8fbst2lpmtM7PHzKwXgJl1AP4V+MdWj1Sk3PKdvZSZ9Rw3LnaznplhL1ig5mkSKNWqm8VAb3fvDzwDPBhu/z7whLvX53uxmU0yszozq9u6dWuJhiRSIvnOrn388SDDP/HEWEbMllyY6/rrYcaM2L0FKYFiavQ1wM3u/q3w/o0A7j4jx/OrCGrxB5nZPGAE0AjsD3QC7nH3G3LtTzV6ibUEL2RX87R0a9UJU2ZWTTAZezLwDsFk7HnuviHynO7u/l54+wzgenf/atb3qSXPhG2GAr3EXqFZzxhP2GaoeVr6tPrMWDMbDdwJVAFz3X26mU0jWM6zyMxmAGOA3cCfgSnu/mrW96hFgV7SpNBC9hhn9xmF/kCpqoJrrlE//CRQCwSRtpaQi500p5iSDiTic6tdU6AXKYcEXewkl0IlnQ4dgvYK3bvH+rOrXVKgFymnhF3spDmFSjqg9gpxo0AvUm75UuOEFL5V0kkWBXqRSsmXGidoLWMx7RW+/W044ghl+JWiQC9SSSlay1hMx8zqarjkkkS8nVRRoBeJg0KF75i2Q86lmLczejQcfnhi3lKiKdCLxEUxhe8EFb0LlXQyNHHb9hToReIooe2QmxMt6Tz55N5vJyNBn2GJo0AvEmeF1t9ffXXsV+hEFTNxe9pp0KNHYj7HEkGBXiQJUrJCJ0OXOiwvBXqRpEjRCp2oYpp+JuwPl9hRoBdJmgS3Q86l2InbBL61WFCgF0mi7BU62dExodl9MSWdDh2COv4XvpC4t1cxCvQiSZeyCdsM9dQpHQV6kbRI2YQttKynTkI/z8pCgV4kTVI6YQvF1fHNgiw/QScRl4UCvUgapXDCNqOYOj4oy49SoBdJq0J1jw4dgg5jCeiBn0sxdfyEVq1KSoFepD0o1AP/nnsSGwUzn2ddu8KLL+avWp1+evtspKZAL9Ke5EuBL7gARoyAbdsSXevQap29KdCLtDeFJmxTUOvQap09KdCLtFeFUt8Er9CJ0lm3CvQi7Vu0HfKuXdDYuPdzUhIBiz3r9vTToXv3xH++7UGBXkSKW6GToghYTB0/TZc9VKAXkT0VquGnZCaz2Dp+VRVcc02y6/gK9CLSvBSfdJWtJXX8JE7eKtCLSG6FImBKJmwzij3rtkOHIOgnpdVCqwO9mZ0C/ByoAua4+61Zj9cC/wK8E276d3efY2ZfBBYAHYCOwC/cfWa+fSnQi1RIoQiY1FQ3j2Lq+JCMt96qQG9mVcBrwDeAemAlMN7dX448pxYY6u6XZ722U7iPT81sf2A9cJy7v5trfwr0IjGQwi6ZuRRbx4d4v/V8gb66iNcPAza5++bwm80HxgIv530V4O47I3c7E2T2IhJ3kyZBv37NT9i6B9Hw+98P+hEkoa6RR03NZ8MfNy5/q4XMW58yBZ54IjkLlIrJ6M8GTnH3S8L73wOGR7P3MKOfAWwlyP6vcve3w8d6AUuA/wNc6+53N7OPScAkgCOOOGLIW2+91fp3JiKl0Y4mbLMVu0TztNMq31+ntaWbYgJ9V+AvYYnmMuC77n5S1vf5ArAQON3d38+1P5VuRGKoUH3DDC66KFiUHvf0toVaUtqp5KrU1gb6GuBmd/9WeP9GAHefkeP5VcCf3f2gZh6bCzzh7o/l2p8CvUjMFeqSmfQF6XnEeYlmawN9NUE55mSCVTUrgfPcfUPkOd3d/b3w9hnA9e7+VTPrCWxz97+a2SHA74Gz3P2lXPtToBdJiEITtim+DFR0gdKSJfHor1OK5ZWjgTsJllfOdffpZjYNqHP3RWY2AxgD7Ab+DExx91fN7BvAvwIOGMGyy9n59qVAL5Ighc6whVTX8KG4dflmcMop8MUvtt3nnk6YEpG2VWjWMmV9dHIpZvK2qiqYvC31oVCgF5G2V+xloFLSRyeXlkzeZpqqDRrU+mvBKNCLSPm142WZGcVO3kLrT8ZSoBeRyigU6Tp0CProTJiQyuw+oyWTtx07wvPPt/xwKNCLSGUVmrFM+bLMqOihePLJva8F06ED3HIL3Hhjy76vAr2IxIdKOk2y6/kNDdC5MyxdqoxeRJKu0LLMdlLSicoE/X39g0aBXkTiqZiLl7eTkk5rtbZ7pYhI28h0ycy1HrGhAX72s+B2OyrplJoCvYhUVnaf4FwlnUx/4NWr21VJpxRUuhGR+ClU0unYEUaPTv2Zti2hGr2IJE+xp5im/EzbYinQi0iyZVbp3H8/7NzZ7pdlNidfoNel/UQk/mpq4N57YdkyuOyyIIvPlqnhjxsX/LtiRdmHGVfK6EUkeYrpDdzOSjrK6EUkXTIZ/oIFcM89QVA32/M5u3bBzJlwwgnB5G47pkAvIsk2aVLQBUwlnZxUuhGR9GjHJR2VbkSkfVBJp1kK9CKSTsWWdMaOTX1JR6UbEUm/Yko6mev6JbSkoxOmREQyiumHf/XVieuYqe6VIiIZmY6ZuS5xuHt30DGzQ4cg6E+cmNgsP0MZvYi0X8WUdCAR7RVUuhERKaSYi6CcfjocfngsM3wFehGRYmQ6ZnbtCi++mPtShzFci69ALyKyLxJ0IXOdMCUisi9Ssha/qEBvZqeY2UYz22RmNzTzeK2ZbTWzNeHXJeH2gWa2wsw2mNk6M/tuqd+AiEibypxt+/zzMHly0DOnquqzxxsbYdGiz862jWHAL1i6MbMq4DXgG0A9sBIY7+4vR55TCwx198uzXnsU4O7+upl9AVgFfNndP8y1P5VuRCT2YrgWv7Wlm2HAJnff7O47gfnA2GJ27O6vufvr4e13gT8B3YobtohITBVT0vnZz+CHP4xFT51iAn0P4O3I/fpwW7azwvLMY2bWK/tBMxsGdALeaOaxSWZWZ2Z1W7duLXLoIiIVVKikkxGDNsmlmoxdDPR29/7AM8CD0QfNrDvwEHCRuzdmv9jdZ7v7UHcf2q2bEn4RSZBiOmY2NsLjjwd1/BNPLHvAL6YFwjtANEPvGW5r4u7bInfnAD/L3DGzA4ElwI/c/Xf7PlQRkZjLtFd47jn48EO444696/iZNslz5pStjl9MoF8JfMnM+hAE+HOB86JPMLPu7v5eeHcM8Eq4vROwAPiVuz9WslGLiMRVTc1nQXvcuFj01ClYunH33cDlwFMEAfwRd99gZtPMbEz4tKnhEsq1wFSgNtz+HeAEoDay9HJgqd+EiEgsFVPHb2yEnTvb9GIoOjNWRKScCi3N7Ngx+GBoYWavNsUiInERreM311OnoSF4rIQlHAV6EZFyi9bxAQYNCrL8hgbo3DmYnC0hBXoRkUqLZvltsAJHgV5EJA6ys/wSUvdKEZGUU6AXEUk5BXoRkZRToBcRSTkFehGRlFOgFxFJudi1QDCzrcBbrfgWhwEflGg4paRxtUxcxwXxHZvG1TJxHRfs29i+6O7N9nmPXaBvLTOry9XvoZI0rpaJ67ggvmPTuFomruOC0o9NpRsRkZRToBcRSbk0BvrKXoU3N42rZeI6Lojv2DSulonruKDEY0tdjV5ERPaUxoxeREQiFOhFRFIuNYHezE4xs41mtsnMbqjgOHqZ2TIzezm8ju4Pwu03m9k7kWvnjq7Q+LaY2UvhGOrCbYea2TNm9nr47yFlHtPRkeOyxsw+MrMrK3HMzGyumf3JzNZHtjV7fCxwV/g7t87MBpd5XP9iZq+G+15gZgeH23ub2V8jx21mW40rz9hy/uzM7MbwmG00s2+VeVz/GRnTFjNbE24v2zHLEyPa7vfM3RP/BVQBbwBHAp2AtcAxFRpLd2BwePsA4DXgGOBm4B9jcKy2AIdlbfsZcEN4+wbgtgr/LP8IfLESx4zgYvaDgfWFjg8wGngSMOCrwO/LPK5vAtXh7dsi4+odfV6FjlmzP7vw/8JaoDPQJ/x/W1WucWU9/q/Aj8t9zPLEiDb7PUtLRj8M2OTum919JzAfGFuJgbj7e+6+Orz9MfAK0KMSY2mBscCD4e0HgXGVGwonA2+4e2vOjt5n7r4c+HPW5lzHZyzwKw/8DjjYzLqXa1zu/rS77w7v/g7o2Rb7LiTHMctlLDDf3T919zeBTQT/f8s6LjMz4DvAw22x73zyxIg2+z1LS6DvAbwduV9PDIKrmfUGBgG/DzddHv7pNbfc5ZEIB542s1VmNinc9rfu/l54+4/A31ZmaACcy57/+eJwzHIdnzj93k0kyPoy+pjZi2b2vJmNqNCYmvvZxeWYjQDed/fXI9vKfsyyYkSb/Z6lJdDHjpntD/wauNLdPwLuBf4OGAi8R/BnYyUc7+6DgW8D/2BmJ0Qf9OBvxYqsuTWzTsAY4NFwU1yOWZNKHp9czOxHwG5gXrjpPeAIdx8EXA38XzM7sMzDit3PLst49kwoyn7MmokRTUr9e5aWQP8O0Ctyv2e4rSLMrCPBD3Ceu/8GwN3fd/cGd28E7qON/lwtxN3fCf/9E7AgHMf7mT8Fw3//VImxEXz4rHb398MxxuKYkfv4VPz3zsxqgdOA88PgQFgW2RbeXkVQBz+qnOPK87OLwzGrBs4E/jOzrdzHrLkYQRv+nqUl0K8EvmRmfcKs8FxgUSUGEtb+fgm84u7/FtkeramdAazPfm0ZxrafmR2QuU0wmbee4FhNCJ82AXi83GML7ZFlxeGYhXIdn0XAheGqiK8C2yN/erc5MzsFuA4Y4+6fRLZ3M7Oq8PaRwJeAzeUaV7jfXD+7RcC5ZtbZzPqEY/tDOccGfB141d3rMxvKecxyxQja8vesHLPM5fgimJl+jeCT+EcVHMfxBH9yrQPWhF+jgYeAl8Lti4DuFRjbkQQrHtYCGzLHCegKLAVeB54FDq3A2PYDtgEHRbaV/ZgRfNC8B+wiqIVenOv4EKyCuDv8nXsJGFrmcW0iqN1mfs9mhs89K/z5rgFWA6dX4Jjl/NkBPwqP2Ubg2+UcV7j9AWBy1nPLdszyxIg2+z1TCwQRkZRLS+lGRERyUKAXEUk5BXoRkZRToBcRSTkFehGRlFOgFxFJOQV6EZGU+/+lL45X+hf+lgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7535 - val_loss: 0.5273 - val_accuracy: 0.7396\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7535 - val_loss: 0.5272 - val_accuracy: 0.7396\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 0.7535 - val_loss: 0.5270 - val_accuracy: 0.7396\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.7535 - val_loss: 0.5268 - val_accuracy: 0.7396\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7535 - val_loss: 0.5267 - val_accuracy: 0.7396\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5171 - accuracy: 0.7535 - val_loss: 0.5265 - val_accuracy: 0.7396\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7535 - val_loss: 0.5263 - val_accuracy: 0.7448\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.5168 - accuracy: 0.7535 - val_loss: 0.5262 - val_accuracy: 0.7448\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5165 - accuracy: 0.7535 - val_loss: 0.5260 - val_accuracy: 0.7448\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 987us/step - loss: 0.5164 - accuracy: 0.7535 - val_loss: 0.5259 - val_accuracy: 0.7448\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7552 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5160 - accuracy: 0.7552 - val_loss: 0.5255 - val_accuracy: 0.7448\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7552 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7552 - val_loss: 0.5252 - val_accuracy: 0.7448\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7552 - val_loss: 0.5251 - val_accuracy: 0.7448\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7552 - val_loss: 0.5249 - val_accuracy: 0.7448\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7552 - val_loss: 0.5247 - val_accuracy: 0.7448\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7552 - val_loss: 0.5246 - val_accuracy: 0.7448\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.5147 - accuracy: 0.7552 - val_loss: 0.5244 - val_accuracy: 0.7448\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7535 - val_loss: 0.5243 - val_accuracy: 0.7448\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.5143 - accuracy: 0.7535 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 977us/step - loss: 0.5142 - accuracy: 0.7535 - val_loss: 0.5240 - val_accuracy: 0.7448\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.7535 - val_loss: 0.5238 - val_accuracy: 0.7448\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.5138 - accuracy: 0.7535 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.7535 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.5134 - accuracy: 0.7535 - val_loss: 0.5234 - val_accuracy: 0.7500\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7535 - val_loss: 0.5232 - val_accuracy: 0.7500\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 979us/step - loss: 0.5131 - accuracy: 0.7535 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7535 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.7535 - val_loss: 0.5228 - val_accuracy: 0.7500\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7535 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7535 - val_loss: 0.5225 - val_accuracy: 0.7500\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.5122 - accuracy: 0.7552 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.5120 - accuracy: 0.7552 - val_loss: 0.5222 - val_accuracy: 0.7500\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.5119 - accuracy: 0.7552 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.5117 - accuracy: 0.7552 - val_loss: 0.5219 - val_accuracy: 0.7500\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.7569 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5113 - accuracy: 0.7569 - val_loss: 0.5216 - val_accuracy: 0.7500\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.7569 - val_loss: 0.5215 - val_accuracy: 0.7500\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7569 - val_loss: 0.5213 - val_accuracy: 0.7500\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.5108 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7587 - val_loss: 0.5210 - val_accuracy: 0.7500\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7587 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7587 - val_loss: 0.5208 - val_accuracy: 0.7500\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7587 - val_loss: 0.5206 - val_accuracy: 0.7500\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.7587 - val_loss: 0.5205 - val_accuracy: 0.7500\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7587 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.7587 - val_loss: 0.5202 - val_accuracy: 0.7500\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5095 - accuracy: 0.7587 - val_loss: 0.5201 - val_accuracy: 0.7500\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5093 - accuracy: 0.7587 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7587 - val_loss: 0.5198 - val_accuracy: 0.7500\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.5090 - accuracy: 0.7587 - val_loss: 0.5196 - val_accuracy: 0.7500\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7587 - val_loss: 0.5195 - val_accuracy: 0.7500\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.5086 - accuracy: 0.7587 - val_loss: 0.5194 - val_accuracy: 0.7500\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7587 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.7587 - val_loss: 0.5191 - val_accuracy: 0.7500\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7604 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.5080 - accuracy: 0.7604 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7604 - val_loss: 0.5187 - val_accuracy: 0.7500\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7604 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.7604 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.7604 - val_loss: 0.5183 - val_accuracy: 0.7500\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7604 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7604 - val_loss: 0.5181 - val_accuracy: 0.7500\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.5069 - accuracy: 0.7604 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7604 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7604 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7604 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5062 - accuracy: 0.7604 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7604 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5059 - accuracy: 0.7604 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.7604 - val_loss: 0.5170 - val_accuracy: 0.7500\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7604 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5055 - accuracy: 0.7604 - val_loss: 0.5168 - val_accuracy: 0.7500\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7622 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7622 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7622 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7622 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5047 - accuracy: 0.7622 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7622 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7622 - val_loss: 0.5159 - val_accuracy: 0.7500\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.5042 - accuracy: 0.7622 - val_loss: 0.5158 - val_accuracy: 0.7500\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7622 - val_loss: 0.5157 - val_accuracy: 0.7500\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7622 - val_loss: 0.5156 - val_accuracy: 0.7500\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7622 - val_loss: 0.5155 - val_accuracy: 0.7500\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5036 - accuracy: 0.7604 - val_loss: 0.5153 - val_accuracy: 0.7500\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5035 - accuracy: 0.7604 - val_loss: 0.5152 - val_accuracy: 0.7500\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7622 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.7604 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7604 - val_loss: 0.5149 - val_accuracy: 0.7552\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.5029 - accuracy: 0.7622 - val_loss: 0.5147 - val_accuracy: 0.7552\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.5027 - accuracy: 0.7604 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7604 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7604 - val_loss: 0.5144 - val_accuracy: 0.7500\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7604 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5021 - accuracy: 0.7604 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.5020 - accuracy: 0.7604 - val_loss: 0.5141 - val_accuracy: 0.7552\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5018 - accuracy: 0.7604 - val_loss: 0.5139 - val_accuracy: 0.7552\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.5017 - accuracy: 0.7604 - val_loss: 0.5138 - val_accuracy: 0.7552\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 0.7622 - val_loss: 0.5137 - val_accuracy: 0.7604\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.7604 - val_loss: 0.5136 - val_accuracy: 0.7656\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7622 - val_loss: 0.5135 - val_accuracy: 0.7656\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.5011 - accuracy: 0.7604 - val_loss: 0.5134 - val_accuracy: 0.7656\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.7604 - val_loss: 0.5133 - val_accuracy: 0.7656\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5008 - accuracy: 0.7604 - val_loss: 0.5132 - val_accuracy: 0.7656\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7604 - val_loss: 0.5131 - val_accuracy: 0.7656\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.5006 - accuracy: 0.7604 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7604 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7604 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5002 - accuracy: 0.7604 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.7639 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4999 - accuracy: 0.7622 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7622 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7622 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7622 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7639 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7622 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7622 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4989 - accuracy: 0.7622 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7622 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4987 - accuracy: 0.7639 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7639 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7622 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7622 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 922us/step - loss: 0.4981 - accuracy: 0.7622 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7622 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 987us/step - loss: 0.4979 - accuracy: 0.7622 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.7622 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7622 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4975 - accuracy: 0.7622 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7622 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7622 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4971 - accuracy: 0.7622 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7622 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7622 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7622 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4966 - accuracy: 0.7622 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.7622 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7622 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 961us/step - loss: 0.4962 - accuracy: 0.7622 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7622 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4960 - accuracy: 0.7622 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7622 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4957 - accuracy: 0.7622 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4956 - accuracy: 0.7622 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.7622 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7622 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4952 - accuracy: 0.7622 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4951 - accuracy: 0.7622 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7622 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7622 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7639 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4946 - accuracy: 0.7639 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 953us/step - loss: 0.4945 - accuracy: 0.7639 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7639 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7639 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7639 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7639 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4939 - accuracy: 0.7622 - val_loss: 0.5079 - val_accuracy: 0.7656\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.4938 - accuracy: 0.7639 - val_loss: 0.5078 - val_accuracy: 0.7656\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7639 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.7622 - val_loss: 0.5077 - val_accuracy: 0.7656\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7639 - val_loss: 0.5076 - val_accuracy: 0.7656\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.7639 - val_loss: 0.5075 - val_accuracy: 0.7656\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4932 - accuracy: 0.7622 - val_loss: 0.5074 - val_accuracy: 0.7656\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7622 - val_loss: 0.5073 - val_accuracy: 0.7656\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7639 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4928 - accuracy: 0.7622 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7656 - val_loss: 0.5071 - val_accuracy: 0.7656\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7622 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7656 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7622 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7656 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7639 - val_loss: 0.5067 - val_accuracy: 0.7656\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7656 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.4919 - accuracy: 0.7639 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7656 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4917 - accuracy: 0.7639 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.7639 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4915 - accuracy: 0.7639 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7639 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4912 - accuracy: 0.7639 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4911 - accuracy: 0.7656 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.7639 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 933us/step - loss: 0.4909 - accuracy: 0.7639 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.7639 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4907 - accuracy: 0.7639 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4906 - accuracy: 0.7639 - val_loss: 0.5056 - val_accuracy: 0.7708\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.7656 - val_loss: 0.5055 - val_accuracy: 0.7708\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4904 - accuracy: 0.7639 - val_loss: 0.5054 - val_accuracy: 0.7708\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.4903 - accuracy: 0.7639 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7639 - val_loss: 0.5053 - val_accuracy: 0.7760\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4901 - accuracy: 0.7639 - val_loss: 0.5052 - val_accuracy: 0.7760\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7656 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 951us/step - loss: 0.4899 - accuracy: 0.7639 - val_loss: 0.5051 - val_accuracy: 0.7760\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7674 - val_loss: 0.5050 - val_accuracy: 0.7760\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4896 - accuracy: 0.7674 - val_loss: 0.5049 - val_accuracy: 0.7760\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 981us/step - loss: 0.4895 - accuracy: 0.7674 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7674 - val_loss: 0.5048 - val_accuracy: 0.7760\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.7674 - val_loss: 0.5047 - val_accuracy: 0.7760\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 937us/step - loss: 0.4892 - accuracy: 0.7674 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7674 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.7674 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 987us/step - loss: 0.4889 - accuracy: 0.7674 - val_loss: 0.5044 - val_accuracy: 0.7760\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7674 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4887 - accuracy: 0.7691 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4886 - accuracy: 0.7674 - val_loss: 0.5042 - val_accuracy: 0.7760\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7691 - val_loss: 0.5041 - val_accuracy: 0.7760\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7691 - val_loss: 0.5041 - val_accuracy: 0.7760\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7691 - val_loss: 0.5040 - val_accuracy: 0.7760\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.7691 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4881 - accuracy: 0.7691 - val_loss: 0.5039 - val_accuracy: 0.7760\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7708 - val_loss: 0.5038 - val_accuracy: 0.7760\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7691 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.4878 - accuracy: 0.7708 - val_loss: 0.5037 - val_accuracy: 0.7760\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7708 - val_loss: 0.5036 - val_accuracy: 0.7760\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7691 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4875 - accuracy: 0.7708 - val_loss: 0.5035 - val_accuracy: 0.7760\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.7708 - val_loss: 0.5034 - val_accuracy: 0.7760\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4873 - accuracy: 0.7708 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7708 - val_loss: 0.5033 - val_accuracy: 0.7760\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4871 - accuracy: 0.7708 - val_loss: 0.5032 - val_accuracy: 0.7760\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7708 - val_loss: 0.5031 - val_accuracy: 0.7760\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4868 - accuracy: 0.7726 - val_loss: 0.5030 - val_accuracy: 0.7760\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7708 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4867 - accuracy: 0.7726 - val_loss: 0.5029 - val_accuracy: 0.7708\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7726 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7726 - val_loss: 0.5028 - val_accuracy: 0.7708\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.7726 - val_loss: 0.5027 - val_accuracy: 0.7708\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4862 - accuracy: 0.7708 - val_loss: 0.5026 - val_accuracy: 0.7708\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7708 - val_loss: 0.5025 - val_accuracy: 0.7708\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7708 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7708 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4858 - accuracy: 0.7708 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7708 - val_loss: 0.5023 - val_accuracy: 0.7708\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7708 - val_loss: 0.5022 - val_accuracy: 0.7708\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7708 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.4854 - accuracy: 0.7708 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4854 - accuracy: 0.7708 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4853 - accuracy: 0.7726 - val_loss: 0.5020 - val_accuracy: 0.7708\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4852 - accuracy: 0.7708 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7726 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7726 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4849 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7708\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4847 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7708\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4845 - accuracy: 0.7708 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4844 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 979us/step - loss: 0.4844 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7708\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7726 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4842 - accuracy: 0.7743 - val_loss: 0.5013 - val_accuracy: 0.7708\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7708 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7743 - val_loss: 0.5012 - val_accuracy: 0.7708\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4839 - accuracy: 0.7708 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4838 - accuracy: 0.7708 - val_loss: 0.5011 - val_accuracy: 0.7708\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 977us/step - loss: 0.4838 - accuracy: 0.7708 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4836 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7708\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7726 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 963us/step - loss: 0.4835 - accuracy: 0.7726 - val_loss: 0.5008 - val_accuracy: 0.7708\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7743 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4833 - accuracy: 0.7726 - val_loss: 0.5007 - val_accuracy: 0.7708\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7726 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7743 - val_loss: 0.5006 - val_accuracy: 0.7708\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7743 - val_loss: 0.5005 - val_accuracy: 0.7708\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7726 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7743 - val_loss: 0.5004 - val_accuracy: 0.7708\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7743 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.7743 - val_loss: 0.5003 - val_accuracy: 0.7708\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4824 - accuracy: 0.7743 - val_loss: 0.5002 - val_accuracy: 0.7708\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7743 - val_loss: 0.5001 - val_accuracy: 0.7708\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.4821 - accuracy: 0.7726 - val_loss: 0.5000 - val_accuracy: 0.7708\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7726 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7726 - val_loss: 0.4999 - val_accuracy: 0.7708\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7726 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4818 - accuracy: 0.7726 - val_loss: 0.4998 - val_accuracy: 0.7708\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.4817 - accuracy: 0.7726 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7726 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7726 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4815 - accuracy: 0.7726 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7726 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7726 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4812 - accuracy: 0.7726 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7726 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.7726 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4810 - accuracy: 0.7726 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7726 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7726 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7726 - val_loss: 0.4992 - val_accuracy: 0.7656\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7726 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7726 - val_loss: 0.4991 - val_accuracy: 0.7656\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4805 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7726 - val_loss: 0.4990 - val_accuracy: 0.7656\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7743 - val_loss: 0.4989 - val_accuracy: 0.7656\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.7743 - val_loss: 0.4988 - val_accuracy: 0.7656\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7743 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4800 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7760 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7726 - val_loss: 0.4986 - val_accuracy: 0.7656\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7726 - val_loss: 0.4985 - val_accuracy: 0.7656\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7726 - val_loss: 0.4984 - val_accuracy: 0.7656\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7708 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 981us/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7708 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7708 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4792 - accuracy: 0.7708 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4791 - accuracy: 0.7708 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7708 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7708 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4788 - accuracy: 0.7691 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 960us/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7691 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7691 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7691 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7691 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4779 - accuracy: 0.7708 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7691 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7691 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7691 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4776 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7691 - val_loss: 0.4973 - val_accuracy: 0.7760\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4774 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7708 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7691 - val_loss: 0.4972 - val_accuracy: 0.7760\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7708 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7708 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.7708 - val_loss: 0.4971 - val_accuracy: 0.7760\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7708 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.7708 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.7708 - val_loss: 0.4970 - val_accuracy: 0.7760\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7708 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4767 - accuracy: 0.7708 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 0.7708 - val_loss: 0.4969 - val_accuracy: 0.7760\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4766 - accuracy: 0.7708 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7708 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7708 - val_loss: 0.4968 - val_accuracy: 0.7760\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7708 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7708 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4763 - accuracy: 0.7708 - val_loss: 0.4967 - val_accuracy: 0.7760\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4763 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4762 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7760\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4760 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7708 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7708 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7708 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7726 - val_loss: 0.4964 - val_accuracy: 0.7760\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4757 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7726 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4756 - accuracy: 0.7743 - val_loss: 0.4963 - val_accuracy: 0.7760\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7743 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7726 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4754 - accuracy: 0.7743 - val_loss: 0.4962 - val_accuracy: 0.7760\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.4752 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7760\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4751 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7760\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4749 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7760\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4747 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4746 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7760\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4957 - val_accuracy: 0.7760\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7760\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7760\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7743 - val_loss: 0.4956 - val_accuracy: 0.7760\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7760 - val_loss: 0.4956 - val_accuracy: 0.7760\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 979us/step - loss: 0.4741 - accuracy: 0.7760 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7743 - val_loss: 0.4955 - val_accuracy: 0.7760\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7726 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.4738 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7743 - val_loss: 0.4954 - val_accuracy: 0.7760\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4737 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4736 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7743 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7743 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4734 - accuracy: 0.7743 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7743 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4734 - accuracy: 0.7743 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4731 - accuracy: 0.7743 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7743 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7743 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7743 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.4729 - accuracy: 0.7743 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4719 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4718 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4717 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4715 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4713 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.4712 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7708\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4710 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4709 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7708\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4708 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.4708 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7743 - val_loss: 0.4940 - val_accuracy: 0.7708\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 981us/step - loss: 0.4705 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.4704 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7760 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4704 - accuracy: 0.7743 - val_loss: 0.4939 - val_accuracy: 0.7708\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4702 - accuracy: 0.7760 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7760 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7708\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4701 - accuracy: 0.7778 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4700 - accuracy: 0.7778 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4699 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7778 - val_loss: 0.4937 - val_accuracy: 0.7708\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7778 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.4697 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7778 - val_loss: 0.4936 - val_accuracy: 0.7708\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7778 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4694 - accuracy: 0.7795 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7778 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4693 - accuracy: 0.7795 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 909us/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.4935 - val_accuracy: 0.7708\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7778 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4692 - accuracy: 0.7778 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7778 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 981us/step - loss: 0.4688 - accuracy: 0.7778 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.4687 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.7778 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4687 - accuracy: 0.7778 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.4686 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 954us/step - loss: 0.4685 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4685 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.4685 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 937us/step - loss: 0.4684 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7778 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4682 - accuracy: 0.7778 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7778 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 961us/step - loss: 0.4682 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4680 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4679 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4679 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.4678 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 981us/step - loss: 0.4677 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4676 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4676 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.4675 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 965us/step - loss: 0.4671 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7778 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4669 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4659 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 981us/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7830 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4646 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.4645 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4644 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7847 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 961us/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4642 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4641 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4641 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 944us/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.4637 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7604\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 979us/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4631 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 961us/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4624 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7882 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 954us/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7604\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 961us/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4920 - val_accuracy: 0.7656\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 897us/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.4611 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 925us/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 965us/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4608 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7865 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7882 - val_loss: 0.4921 - val_accuracy: 0.7656\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7656\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7865 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 960us/step - loss: 0.4604 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7899 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 919us/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4603 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.7552\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x177d0f850>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7137 - accuracy: 0.5069 - val_loss: 0.7224 - val_accuracy: 0.5104\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.5295 - val_loss: 0.7196 - val_accuracy: 0.5417\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7081 - accuracy: 0.5417 - val_loss: 0.7170 - val_accuracy: 0.5573\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.5642 - val_loss: 0.7146 - val_accuracy: 0.5833\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.5764 - val_loss: 0.7122 - val_accuracy: 0.5885\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7007 - accuracy: 0.5972 - val_loss: 0.7100 - val_accuracy: 0.5938\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6985 - accuracy: 0.6181 - val_loss: 0.7078 - val_accuracy: 0.5990\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6963 - accuracy: 0.6285 - val_loss: 0.7058 - val_accuracy: 0.6146\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6942 - accuracy: 0.6354 - val_loss: 0.7038 - val_accuracy: 0.6198\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.6510 - val_loss: 0.7020 - val_accuracy: 0.6354\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6904 - accuracy: 0.6528 - val_loss: 0.7002 - val_accuracy: 0.6354\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.6510 - val_loss: 0.6985 - val_accuracy: 0.6458\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.6510 - val_loss: 0.6969 - val_accuracy: 0.6458\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6854 - accuracy: 0.6528 - val_loss: 0.6954 - val_accuracy: 0.6458\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6838 - accuracy: 0.6545 - val_loss: 0.6939 - val_accuracy: 0.6458\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.6823 - accuracy: 0.6545 - val_loss: 0.6924 - val_accuracy: 0.6458\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.6562 - val_loss: 0.6910 - val_accuracy: 0.6458\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.6580 - val_loss: 0.6896 - val_accuracy: 0.6458\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.6580 - val_loss: 0.6883 - val_accuracy: 0.6458\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.6580 - val_loss: 0.6870 - val_accuracy: 0.6458\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.6580 - val_loss: 0.6858 - val_accuracy: 0.6406\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.6742 - accuracy: 0.6580 - val_loss: 0.6846 - val_accuracy: 0.6406\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6731 - accuracy: 0.6580 - val_loss: 0.6834 - val_accuracy: 0.6406\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6719 - accuracy: 0.6562 - val_loss: 0.6823 - val_accuracy: 0.6406\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6708 - accuracy: 0.6562 - val_loss: 0.6812 - val_accuracy: 0.6406\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6697 - accuracy: 0.6545 - val_loss: 0.6802 - val_accuracy: 0.6406\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6687 - accuracy: 0.6545 - val_loss: 0.6791 - val_accuracy: 0.6406\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.6677 - accuracy: 0.6545 - val_loss: 0.6781 - val_accuracy: 0.6406\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6667 - accuracy: 0.6545 - val_loss: 0.6772 - val_accuracy: 0.6406\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.6658 - accuracy: 0.6545 - val_loss: 0.6762 - val_accuracy: 0.6406\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.6545 - val_loss: 0.6753 - val_accuracy: 0.6406\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6640 - accuracy: 0.6545 - val_loss: 0.6744 - val_accuracy: 0.6406\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6631 - accuracy: 0.6545 - val_loss: 0.6736 - val_accuracy: 0.6406\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 939us/step - loss: 0.6623 - accuracy: 0.6545 - val_loss: 0.6727 - val_accuracy: 0.6406\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.6545 - val_loss: 0.6719 - val_accuracy: 0.6406\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6545 - val_loss: 0.6711 - val_accuracy: 0.6406\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6545 - val_loss: 0.6704 - val_accuracy: 0.6406\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6545 - val_loss: 0.6696 - val_accuracy: 0.6406\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6545 - val_loss: 0.6689 - val_accuracy: 0.6406\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6545 - val_loss: 0.6682 - val_accuracy: 0.6406\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6545 - val_loss: 0.6675 - val_accuracy: 0.6406\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6545 - val_loss: 0.6668 - val_accuracy: 0.6406\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6545 - val_loss: 0.6661 - val_accuracy: 0.6406\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6545 - val_loss: 0.6654 - val_accuracy: 0.6406\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.6545 - val_loss: 0.6648 - val_accuracy: 0.6406\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6545 - val_loss: 0.6642 - val_accuracy: 0.6406\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6545 - val_loss: 0.6636 - val_accuracy: 0.6406\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6545 - val_loss: 0.6629 - val_accuracy: 0.6406\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6545 - val_loss: 0.6623 - val_accuracy: 0.6406\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6545 - val_loss: 0.6617 - val_accuracy: 0.6406\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6545 - val_loss: 0.6612 - val_accuracy: 0.6406\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6545 - val_loss: 0.6606 - val_accuracy: 0.6406\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.6492 - accuracy: 0.6545 - val_loss: 0.6601 - val_accuracy: 0.6406\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6545 - val_loss: 0.6595 - val_accuracy: 0.6406\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6545 - val_loss: 0.6590 - val_accuracy: 0.6406\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6545 - val_loss: 0.6585 - val_accuracy: 0.6406\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6545 - val_loss: 0.6580 - val_accuracy: 0.6406\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.6545 - val_loss: 0.6575 - val_accuracy: 0.6406\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.6545 - val_loss: 0.6570 - val_accuracy: 0.6406\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6452 - accuracy: 0.6545 - val_loss: 0.6565 - val_accuracy: 0.6406\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6545 - val_loss: 0.6560 - val_accuracy: 0.6406\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.6545 - val_loss: 0.6555 - val_accuracy: 0.6406\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6435 - accuracy: 0.6545 - val_loss: 0.6550 - val_accuracy: 0.6406\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.6545 - val_loss: 0.6545 - val_accuracy: 0.6406\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6545 - val_loss: 0.6541 - val_accuracy: 0.6406\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.6545 - val_loss: 0.6536 - val_accuracy: 0.6406\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6545 - val_loss: 0.6531 - val_accuracy: 0.6406\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6545 - val_loss: 0.6526 - val_accuracy: 0.6406\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6545 - val_loss: 0.6522 - val_accuracy: 0.6406\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.6545 - val_loss: 0.6517 - val_accuracy: 0.6406\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.6390 - accuracy: 0.6545 - val_loss: 0.6512 - val_accuracy: 0.6406\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6384 - accuracy: 0.6545 - val_loss: 0.6508 - val_accuracy: 0.6406\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6545 - val_loss: 0.6503 - val_accuracy: 0.6406\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.6545 - val_loss: 0.6499 - val_accuracy: 0.6406\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6368 - accuracy: 0.6545 - val_loss: 0.6495 - val_accuracy: 0.6406\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.6545 - val_loss: 0.6490 - val_accuracy: 0.6406\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6357 - accuracy: 0.6545 - val_loss: 0.6486 - val_accuracy: 0.6406\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6545 - val_loss: 0.6482 - val_accuracy: 0.6406\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.6347 - accuracy: 0.6545 - val_loss: 0.6478 - val_accuracy: 0.6406\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6342 - accuracy: 0.6545 - val_loss: 0.6473 - val_accuracy: 0.6406\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6545 - val_loss: 0.6469 - val_accuracy: 0.6406\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.6545 - val_loss: 0.6464 - val_accuracy: 0.6406\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.6545 - val_loss: 0.6460 - val_accuracy: 0.6406\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.6321 - accuracy: 0.6545 - val_loss: 0.6456 - val_accuracy: 0.6406\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6545 - val_loss: 0.6451 - val_accuracy: 0.6406\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.6545 - val_loss: 0.6447 - val_accuracy: 0.6406\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6305 - accuracy: 0.6545 - val_loss: 0.6442 - val_accuracy: 0.6406\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6545 - val_loss: 0.6438 - val_accuracy: 0.6406\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.6545 - val_loss: 0.6433 - val_accuracy: 0.6406\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.6545 - val_loss: 0.6429 - val_accuracy: 0.6406\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6545 - val_loss: 0.6425 - val_accuracy: 0.6406\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6545 - val_loss: 0.6420 - val_accuracy: 0.6406\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.6545 - val_loss: 0.6416 - val_accuracy: 0.6406\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.6267 - accuracy: 0.6545 - val_loss: 0.6411 - val_accuracy: 0.6406\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.6545 - val_loss: 0.6407 - val_accuracy: 0.6406\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6257 - accuracy: 0.6545 - val_loss: 0.6402 - val_accuracy: 0.6406\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6251 - accuracy: 0.6545 - val_loss: 0.6398 - val_accuracy: 0.6406\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6246 - accuracy: 0.6545 - val_loss: 0.6394 - val_accuracy: 0.6406\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6241 - accuracy: 0.6545 - val_loss: 0.6390 - val_accuracy: 0.6406\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.6545 - val_loss: 0.6385 - val_accuracy: 0.6406\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.6545 - val_loss: 0.6381 - val_accuracy: 0.6406\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.6545 - val_loss: 0.6377 - val_accuracy: 0.6406\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.6545 - val_loss: 0.6372 - val_accuracy: 0.6406\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6216 - accuracy: 0.6545 - val_loss: 0.6368 - val_accuracy: 0.6406\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6210 - accuracy: 0.6545 - val_loss: 0.6364 - val_accuracy: 0.6406\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6205 - accuracy: 0.6545 - val_loss: 0.6360 - val_accuracy: 0.6406\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.6545 - val_loss: 0.6356 - val_accuracy: 0.6406\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6195 - accuracy: 0.6545 - val_loss: 0.6351 - val_accuracy: 0.6406\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.6189 - accuracy: 0.6545 - val_loss: 0.6347 - val_accuracy: 0.6406\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6184 - accuracy: 0.6545 - val_loss: 0.6342 - val_accuracy: 0.6406\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6179 - accuracy: 0.6545 - val_loss: 0.6338 - val_accuracy: 0.6406\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6174 - accuracy: 0.6545 - val_loss: 0.6333 - val_accuracy: 0.6406\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.6545 - val_loss: 0.6329 - val_accuracy: 0.6406\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.6545 - val_loss: 0.6324 - val_accuracy: 0.6406\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.6545 - val_loss: 0.6320 - val_accuracy: 0.6406\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6152 - accuracy: 0.6545 - val_loss: 0.6315 - val_accuracy: 0.6406\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6147 - accuracy: 0.6545 - val_loss: 0.6310 - val_accuracy: 0.6406\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.6545 - val_loss: 0.6306 - val_accuracy: 0.6406\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 981us/step - loss: 0.6137 - accuracy: 0.6545 - val_loss: 0.6301 - val_accuracy: 0.6406\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6132 - accuracy: 0.6545 - val_loss: 0.6297 - val_accuracy: 0.6406\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.6545 - val_loss: 0.6292 - val_accuracy: 0.6406\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6121 - accuracy: 0.6545 - val_loss: 0.6288 - val_accuracy: 0.6406\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.6116 - accuracy: 0.6545 - val_loss: 0.6283 - val_accuracy: 0.6406\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6111 - accuracy: 0.6545 - val_loss: 0.6279 - val_accuracy: 0.6406\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6106 - accuracy: 0.6545 - val_loss: 0.6274 - val_accuracy: 0.6406\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6101 - accuracy: 0.6545 - val_loss: 0.6270 - val_accuracy: 0.6406\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6096 - accuracy: 0.6545 - val_loss: 0.6266 - val_accuracy: 0.6406\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.6091 - accuracy: 0.6545 - val_loss: 0.6261 - val_accuracy: 0.6406\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.6545 - val_loss: 0.6256 - val_accuracy: 0.6406\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6080 - accuracy: 0.6545 - val_loss: 0.6252 - val_accuracy: 0.6406\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.6545 - val_loss: 0.6247 - val_accuracy: 0.6406\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6069 - accuracy: 0.6545 - val_loss: 0.6243 - val_accuracy: 0.6406\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6545 - val_loss: 0.6239 - val_accuracy: 0.6406\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 951us/step - loss: 0.6059 - accuracy: 0.6545 - val_loss: 0.6234 - val_accuracy: 0.6406\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6053 - accuracy: 0.6545 - val_loss: 0.6230 - val_accuracy: 0.6406\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.6545 - val_loss: 0.6225 - val_accuracy: 0.6406\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.6545 - val_loss: 0.6220 - val_accuracy: 0.6406\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6037 - accuracy: 0.6545 - val_loss: 0.6215 - val_accuracy: 0.6406\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 951us/step - loss: 0.6031 - accuracy: 0.6545 - val_loss: 0.6210 - val_accuracy: 0.6406\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6545 - val_loss: 0.6205 - val_accuracy: 0.6406\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6021 - accuracy: 0.6545 - val_loss: 0.6200 - val_accuracy: 0.6406\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.6545 - val_loss: 0.6195 - val_accuracy: 0.6406\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.6545 - val_loss: 0.6190 - val_accuracy: 0.6406\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.6004 - accuracy: 0.6545 - val_loss: 0.6185 - val_accuracy: 0.6406\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.6545 - val_loss: 0.6180 - val_accuracy: 0.6406\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5993 - accuracy: 0.6545 - val_loss: 0.6175 - val_accuracy: 0.6406\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 987us/step - loss: 0.5987 - accuracy: 0.6545 - val_loss: 0.6170 - val_accuracy: 0.6406\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.6545 - val_loss: 0.6165 - val_accuracy: 0.6406\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.6545 - val_loss: 0.6159 - val_accuracy: 0.6406\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.6545 - val_loss: 0.6154 - val_accuracy: 0.6406\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5964 - accuracy: 0.6545 - val_loss: 0.6149 - val_accuracy: 0.6406\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5958 - accuracy: 0.6545 - val_loss: 0.6143 - val_accuracy: 0.6406\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.6545 - val_loss: 0.6138 - val_accuracy: 0.6406\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.6545 - val_loss: 0.6132 - val_accuracy: 0.6406\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5941 - accuracy: 0.6562 - val_loss: 0.6126 - val_accuracy: 0.6406\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5934 - accuracy: 0.6562 - val_loss: 0.6121 - val_accuracy: 0.6406\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6562 - val_loss: 0.6115 - val_accuracy: 0.6406\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.6562 - val_loss: 0.6110 - val_accuracy: 0.6406\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5916 - accuracy: 0.6562 - val_loss: 0.6104 - val_accuracy: 0.6406\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5910 - accuracy: 0.6562 - val_loss: 0.6098 - val_accuracy: 0.6406\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5904 - accuracy: 0.6562 - val_loss: 0.6093 - val_accuracy: 0.6406\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.6562 - val_loss: 0.6087 - val_accuracy: 0.6406\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5892 - accuracy: 0.6562 - val_loss: 0.6081 - val_accuracy: 0.6406\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5885 - accuracy: 0.6562 - val_loss: 0.6075 - val_accuracy: 0.6406\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.6562 - val_loss: 0.6070 - val_accuracy: 0.6406\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5873 - accuracy: 0.6562 - val_loss: 0.6064 - val_accuracy: 0.6406\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5867 - accuracy: 0.6562 - val_loss: 0.6058 - val_accuracy: 0.6406\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5860 - accuracy: 0.6562 - val_loss: 0.6052 - val_accuracy: 0.6406\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.6562 - val_loss: 0.6046 - val_accuracy: 0.6406\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5848 - accuracy: 0.6562 - val_loss: 0.6041 - val_accuracy: 0.6406\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.6562 - val_loss: 0.6035 - val_accuracy: 0.6406\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5835 - accuracy: 0.6562 - val_loss: 0.6029 - val_accuracy: 0.6406\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.6562 - val_loss: 0.6023 - val_accuracy: 0.6406\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5822 - accuracy: 0.6562 - val_loss: 0.6017 - val_accuracy: 0.6406\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.6562 - val_loss: 0.6011 - val_accuracy: 0.6406\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.6562 - val_loss: 0.6006 - val_accuracy: 0.6406\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5803 - accuracy: 0.6562 - val_loss: 0.6000 - val_accuracy: 0.6406\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.6562 - val_loss: 0.5994 - val_accuracy: 0.6406\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.6562 - val_loss: 0.5988 - val_accuracy: 0.6406\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5784 - accuracy: 0.6580 - val_loss: 0.5982 - val_accuracy: 0.6406\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.6597 - val_loss: 0.5976 - val_accuracy: 0.6406\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5771 - accuracy: 0.6597 - val_loss: 0.5971 - val_accuracy: 0.6406\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.6597 - val_loss: 0.5965 - val_accuracy: 0.6406\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.6597 - val_loss: 0.5959 - val_accuracy: 0.6458\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.6615 - val_loss: 0.5953 - val_accuracy: 0.6458\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.6615 - val_loss: 0.5947 - val_accuracy: 0.6458\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5737 - accuracy: 0.6632 - val_loss: 0.5941 - val_accuracy: 0.6458\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.6632 - val_loss: 0.5936 - val_accuracy: 0.6458\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.6632 - val_loss: 0.5930 - val_accuracy: 0.6458\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.6632 - val_loss: 0.5924 - val_accuracy: 0.6458\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.6632 - val_loss: 0.5918 - val_accuracy: 0.6458\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.6632 - val_loss: 0.5913 - val_accuracy: 0.6458\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.6649 - val_loss: 0.5907 - val_accuracy: 0.6458\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.6649 - val_loss: 0.5901 - val_accuracy: 0.6458\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 979us/step - loss: 0.5684 - accuracy: 0.6667 - val_loss: 0.5895 - val_accuracy: 0.6458\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.6667 - val_loss: 0.5889 - val_accuracy: 0.6458\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.6667 - val_loss: 0.5883 - val_accuracy: 0.6458\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 961us/step - loss: 0.5663 - accuracy: 0.6667 - val_loss: 0.5877 - val_accuracy: 0.6458\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.6649 - val_loss: 0.5871 - val_accuracy: 0.6458\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.6649 - val_loss: 0.5865 - val_accuracy: 0.6458\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.6649 - val_loss: 0.5860 - val_accuracy: 0.6458\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.6632 - val_loss: 0.5854 - val_accuracy: 0.6458\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.6632 - val_loss: 0.5848 - val_accuracy: 0.6458\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.6632 - val_loss: 0.5842 - val_accuracy: 0.6458\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.6632 - val_loss: 0.5836 - val_accuracy: 0.6458\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.6632 - val_loss: 0.5830 - val_accuracy: 0.6458\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.6632 - val_loss: 0.5824 - val_accuracy: 0.6458\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.6632 - val_loss: 0.5818 - val_accuracy: 0.6458\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.6632 - val_loss: 0.5812 - val_accuracy: 0.6458\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5582 - accuracy: 0.6632 - val_loss: 0.5806 - val_accuracy: 0.6458\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.6649 - val_loss: 0.5801 - val_accuracy: 0.6458\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5568 - accuracy: 0.6649 - val_loss: 0.5795 - val_accuracy: 0.6458\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5562 - accuracy: 0.6649 - val_loss: 0.5789 - val_accuracy: 0.6458\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5555 - accuracy: 0.6649 - val_loss: 0.5783 - val_accuracy: 0.6458\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.6649 - val_loss: 0.5778 - val_accuracy: 0.6458\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.6649 - val_loss: 0.5772 - val_accuracy: 0.6458\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.6649 - val_loss: 0.5767 - val_accuracy: 0.6458\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5528 - accuracy: 0.6649 - val_loss: 0.5761 - val_accuracy: 0.6458\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5522 - accuracy: 0.6649 - val_loss: 0.5756 - val_accuracy: 0.6458\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.5515 - accuracy: 0.6649 - val_loss: 0.5750 - val_accuracy: 0.6458\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5508 - accuracy: 0.6649 - val_loss: 0.5744 - val_accuracy: 0.6458\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5501 - accuracy: 0.6667 - val_loss: 0.5739 - val_accuracy: 0.6458\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5495 - accuracy: 0.6667 - val_loss: 0.5733 - val_accuracy: 0.6458\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 940us/step - loss: 0.5488 - accuracy: 0.6667 - val_loss: 0.5728 - val_accuracy: 0.6458\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.6667 - val_loss: 0.5722 - val_accuracy: 0.6458\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.6684 - val_loss: 0.5717 - val_accuracy: 0.6510\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5468 - accuracy: 0.6684 - val_loss: 0.5711 - val_accuracy: 0.6510\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 987us/step - loss: 0.5461 - accuracy: 0.6701 - val_loss: 0.5706 - val_accuracy: 0.6510\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.6701 - val_loss: 0.5700 - val_accuracy: 0.6510\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.6701 - val_loss: 0.5695 - val_accuracy: 0.6510\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.5441 - accuracy: 0.6701 - val_loss: 0.5689 - val_accuracy: 0.6510\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.5435 - accuracy: 0.6701 - val_loss: 0.5684 - val_accuracy: 0.6510\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.5428 - accuracy: 0.6736 - val_loss: 0.5678 - val_accuracy: 0.6562\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5422 - accuracy: 0.6736 - val_loss: 0.5673 - val_accuracy: 0.6562\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.6719 - val_loss: 0.5667 - val_accuracy: 0.6562\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.5409 - accuracy: 0.6701 - val_loss: 0.5662 - val_accuracy: 0.6615\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5403 - accuracy: 0.6701 - val_loss: 0.5657 - val_accuracy: 0.6615\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5396 - accuracy: 0.6701 - val_loss: 0.5651 - val_accuracy: 0.6667\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.6701 - val_loss: 0.5646 - val_accuracy: 0.6667\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.6701 - val_loss: 0.5641 - val_accuracy: 0.6615\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.5377 - accuracy: 0.6719 - val_loss: 0.5635 - val_accuracy: 0.6615\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.6719 - val_loss: 0.5630 - val_accuracy: 0.6667\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.6719 - val_loss: 0.5625 - val_accuracy: 0.6667\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5358 - accuracy: 0.6719 - val_loss: 0.5620 - val_accuracy: 0.6667\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5352 - accuracy: 0.6719 - val_loss: 0.5614 - val_accuracy: 0.6667\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.5345 - accuracy: 0.6736 - val_loss: 0.5609 - val_accuracy: 0.6667\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.6736 - val_loss: 0.5604 - val_accuracy: 0.6667\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.5333 - accuracy: 0.6736 - val_loss: 0.5599 - val_accuracy: 0.6667\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.6736 - val_loss: 0.5594 - val_accuracy: 0.6667\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 969us/step - loss: 0.5321 - accuracy: 0.6753 - val_loss: 0.5589 - val_accuracy: 0.6667\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.5315 - accuracy: 0.6736 - val_loss: 0.5584 - val_accuracy: 0.6667\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5309 - accuracy: 0.6736 - val_loss: 0.5579 - val_accuracy: 0.6667\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.6736 - val_loss: 0.5574 - val_accuracy: 0.6667\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.6736 - val_loss: 0.5569 - val_accuracy: 0.6667\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.6753 - val_loss: 0.5564 - val_accuracy: 0.6667\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.6788 - val_loss: 0.5559 - val_accuracy: 0.6667\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.6788 - val_loss: 0.5554 - val_accuracy: 0.6667\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.6823 - val_loss: 0.5549 - val_accuracy: 0.6667\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.5267 - accuracy: 0.6823 - val_loss: 0.5545 - val_accuracy: 0.6667\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.6823 - val_loss: 0.5540 - val_accuracy: 0.6667\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5256 - accuracy: 0.6823 - val_loss: 0.5536 - val_accuracy: 0.6719\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.6823 - val_loss: 0.5531 - val_accuracy: 0.6719\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.5245 - accuracy: 0.6806 - val_loss: 0.5526 - val_accuracy: 0.6719\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5240 - accuracy: 0.6840 - val_loss: 0.5522 - val_accuracy: 0.6719\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.6858 - val_loss: 0.5517 - val_accuracy: 0.6719\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.6858 - val_loss: 0.5513 - val_accuracy: 0.6719\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5223 - accuracy: 0.6875 - val_loss: 0.5509 - val_accuracy: 0.6719\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.6892 - val_loss: 0.5504 - val_accuracy: 0.6771\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 963us/step - loss: 0.5212 - accuracy: 0.6910 - val_loss: 0.5499 - val_accuracy: 0.6823\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.6910 - val_loss: 0.5495 - val_accuracy: 0.6823\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.6910 - val_loss: 0.5491 - val_accuracy: 0.6823\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.5197 - accuracy: 0.6892 - val_loss: 0.5486 - val_accuracy: 0.6875\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5192 - accuracy: 0.6892 - val_loss: 0.5482 - val_accuracy: 0.6875\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5187 - accuracy: 0.6892 - val_loss: 0.5477 - val_accuracy: 0.6875\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.5182 - accuracy: 0.6910 - val_loss: 0.5473 - val_accuracy: 0.6875\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.6910 - val_loss: 0.5469 - val_accuracy: 0.6875\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.5171 - accuracy: 0.6910 - val_loss: 0.5464 - val_accuracy: 0.6875\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.5166 - accuracy: 0.6927 - val_loss: 0.5460 - val_accuracy: 0.6927\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.5161 - accuracy: 0.6927 - val_loss: 0.5456 - val_accuracy: 0.6927\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.6927 - val_loss: 0.5452 - val_accuracy: 0.6875\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.6927 - val_loss: 0.5448 - val_accuracy: 0.6875\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.5146 - accuracy: 0.6927 - val_loss: 0.5443 - val_accuracy: 0.6927\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.6927 - val_loss: 0.5439 - val_accuracy: 0.6927\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.6944 - val_loss: 0.5435 - val_accuracy: 0.6927\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.6944 - val_loss: 0.5431 - val_accuracy: 0.6927\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.6944 - val_loss: 0.5427 - val_accuracy: 0.6927\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.5122 - accuracy: 0.6944 - val_loss: 0.5423 - val_accuracy: 0.6927\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.6962 - val_loss: 0.5419 - val_accuracy: 0.6927\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.5112 - accuracy: 0.6962 - val_loss: 0.5415 - val_accuracy: 0.6927\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.6962 - val_loss: 0.5411 - val_accuracy: 0.6927\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.6979 - val_loss: 0.5408 - val_accuracy: 0.6927\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7031 - val_loss: 0.5404 - val_accuracy: 0.6927\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7066 - val_loss: 0.5400 - val_accuracy: 0.6979\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7066 - val_loss: 0.5396 - val_accuracy: 0.7031\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7066 - val_loss: 0.5393 - val_accuracy: 0.7031\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7066 - val_loss: 0.5389 - val_accuracy: 0.7031\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.5077 - accuracy: 0.7101 - val_loss: 0.5386 - val_accuracy: 0.7031\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.5072 - accuracy: 0.7101 - val_loss: 0.5382 - val_accuracy: 0.7031\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5068 - accuracy: 0.7101 - val_loss: 0.5378 - val_accuracy: 0.7031\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7101 - val_loss: 0.5374 - val_accuracy: 0.7031\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.5059 - accuracy: 0.7101 - val_loss: 0.5371 - val_accuracy: 0.7031\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.5054 - accuracy: 0.7101 - val_loss: 0.5367 - val_accuracy: 0.7031\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7101 - val_loss: 0.5364 - val_accuracy: 0.7031\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7101 - val_loss: 0.5360 - val_accuracy: 0.7031\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.5041 - accuracy: 0.7101 - val_loss: 0.5356 - val_accuracy: 0.7031\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.7066 - val_loss: 0.5353 - val_accuracy: 0.6979\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 933us/step - loss: 0.5032 - accuracy: 0.7066 - val_loss: 0.5350 - val_accuracy: 0.7031\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7066 - val_loss: 0.5346 - val_accuracy: 0.7031\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7066 - val_loss: 0.5343 - val_accuracy: 0.7031\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7083 - val_loss: 0.5339 - val_accuracy: 0.7083\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.7083 - val_loss: 0.5336 - val_accuracy: 0.7083\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7083 - val_loss: 0.5333 - val_accuracy: 0.7083\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7101 - val_loss: 0.5329 - val_accuracy: 0.7083\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7118 - val_loss: 0.5326 - val_accuracy: 0.7083\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.7135 - val_loss: 0.5323 - val_accuracy: 0.7083\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7135 - val_loss: 0.5320 - val_accuracy: 0.7031\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7118 - val_loss: 0.5317 - val_accuracy: 0.7031\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7101 - val_loss: 0.5314 - val_accuracy: 0.7031\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4984 - accuracy: 0.7118 - val_loss: 0.5311 - val_accuracy: 0.7031\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7118 - val_loss: 0.5308 - val_accuracy: 0.7031\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.7118 - val_loss: 0.5305 - val_accuracy: 0.7031\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.4972 - accuracy: 0.7118 - val_loss: 0.5302 - val_accuracy: 0.7031\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7101 - val_loss: 0.5299 - val_accuracy: 0.7031\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7118 - val_loss: 0.5296 - val_accuracy: 0.7031\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7118 - val_loss: 0.5294 - val_accuracy: 0.7031\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7135 - val_loss: 0.5291 - val_accuracy: 0.7083\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4954 - accuracy: 0.7153 - val_loss: 0.5288 - val_accuracy: 0.7135\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4950 - accuracy: 0.7170 - val_loss: 0.5285 - val_accuracy: 0.7135\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7170 - val_loss: 0.5283 - val_accuracy: 0.7135\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.4944 - accuracy: 0.7170 - val_loss: 0.5280 - val_accuracy: 0.7135\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7188 - val_loss: 0.5278 - val_accuracy: 0.7135\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7188 - val_loss: 0.5275 - val_accuracy: 0.7135\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4934 - accuracy: 0.7170 - val_loss: 0.5273 - val_accuracy: 0.7135\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7170 - val_loss: 0.5270 - val_accuracy: 0.7135\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 985us/step - loss: 0.4927 - accuracy: 0.7188 - val_loss: 0.5268 - val_accuracy: 0.7135\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.4924 - accuracy: 0.7188 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7188 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7205 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7188 - val_loss: 0.5258 - val_accuracy: 0.7188\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4911 - accuracy: 0.7188 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4908 - accuracy: 0.7188 - val_loss: 0.5254 - val_accuracy: 0.7188\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4905 - accuracy: 0.7188 - val_loss: 0.5252 - val_accuracy: 0.7188\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7170 - val_loss: 0.5249 - val_accuracy: 0.7188\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7170 - val_loss: 0.5247 - val_accuracy: 0.7188\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.4897 - accuracy: 0.7170 - val_loss: 0.5245 - val_accuracy: 0.7135\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7170 - val_loss: 0.5244 - val_accuracy: 0.7135\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.7153 - val_loss: 0.5242 - val_accuracy: 0.7135\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7153 - val_loss: 0.5240 - val_accuracy: 0.7135\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7153 - val_loss: 0.5238 - val_accuracy: 0.7135\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7153 - val_loss: 0.5237 - val_accuracy: 0.7135\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4880 - accuracy: 0.7135 - val_loss: 0.5235 - val_accuracy: 0.7135\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7118 - val_loss: 0.5233 - val_accuracy: 0.7135\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7118 - val_loss: 0.5232 - val_accuracy: 0.7135\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.4873 - accuracy: 0.7101 - val_loss: 0.5230 - val_accuracy: 0.7135\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7083 - val_loss: 0.5228 - val_accuracy: 0.7188\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7083 - val_loss: 0.5227 - val_accuracy: 0.7188\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7083 - val_loss: 0.5225 - val_accuracy: 0.7188\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7101 - val_loss: 0.5224 - val_accuracy: 0.7188\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7101 - val_loss: 0.5222 - val_accuracy: 0.7188\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4858 - accuracy: 0.7118 - val_loss: 0.5221 - val_accuracy: 0.7188\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7118 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4853 - accuracy: 0.7118 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7118 - val_loss: 0.5216 - val_accuracy: 0.7188\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4849 - accuracy: 0.7118 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7118 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7170 - val_loss: 0.5213 - val_accuracy: 0.7188\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.4843 - accuracy: 0.7205 - val_loss: 0.5211 - val_accuracy: 0.7188\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7205 - val_loss: 0.5210 - val_accuracy: 0.7135\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4839 - accuracy: 0.7205 - val_loss: 0.5209 - val_accuracy: 0.7135\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.7222 - val_loss: 0.5208 - val_accuracy: 0.7188\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7222 - val_loss: 0.5207 - val_accuracy: 0.7188\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 954us/step - loss: 0.4833 - accuracy: 0.7205 - val_loss: 0.5206 - val_accuracy: 0.7188\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.7222 - val_loss: 0.5204 - val_accuracy: 0.7188\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4829 - accuracy: 0.7274 - val_loss: 0.5203 - val_accuracy: 0.7188\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4827 - accuracy: 0.7292 - val_loss: 0.5202 - val_accuracy: 0.7240\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4825 - accuracy: 0.7292 - val_loss: 0.5201 - val_accuracy: 0.7240\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4824 - accuracy: 0.7292 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7309 - val_loss: 0.5199 - val_accuracy: 0.7240\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7292 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4818 - accuracy: 0.7292 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7309 - val_loss: 0.5197 - val_accuracy: 0.7240\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.7309 - val_loss: 0.5196 - val_accuracy: 0.7292\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7309 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4812 - accuracy: 0.7448 - val_loss: 0.5194 - val_accuracy: 0.7240\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4810 - accuracy: 0.7448 - val_loss: 0.5194 - val_accuracy: 0.7240\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7448 - val_loss: 0.5193 - val_accuracy: 0.7240\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4806 - accuracy: 0.7448 - val_loss: 0.5192 - val_accuracy: 0.7240\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7448 - val_loss: 0.5191 - val_accuracy: 0.7240\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7465 - val_loss: 0.5191 - val_accuracy: 0.7240\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4802 - accuracy: 0.7431 - val_loss: 0.5190 - val_accuracy: 0.7240\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4800 - accuracy: 0.7431 - val_loss: 0.5189 - val_accuracy: 0.7240\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4799 - accuracy: 0.7431 - val_loss: 0.5189 - val_accuracy: 0.7188\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7431 - val_loss: 0.5188 - val_accuracy: 0.7240\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7448 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7448 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7448 - val_loss: 0.5186 - val_accuracy: 0.7292\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4791 - accuracy: 0.7431 - val_loss: 0.5186 - val_accuracy: 0.7292\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4790 - accuracy: 0.7431 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.7431 - val_loss: 0.5185 - val_accuracy: 0.7292\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7431 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.7431 - val_loss: 0.5184 - val_accuracy: 0.7292\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4785 - accuracy: 0.7431 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7465 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.7448 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7448 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7448 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.7448 - val_loss: 0.5181 - val_accuracy: 0.7292\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7448 - val_loss: 0.5181 - val_accuracy: 0.7292\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7448 - val_loss: 0.5181 - val_accuracy: 0.7240\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4774 - accuracy: 0.7448 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4773 - accuracy: 0.7448 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.7448 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.4771 - accuracy: 0.7448 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7448 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.7448 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7448 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7448 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7448 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.7448 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4763 - accuracy: 0.7448 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4762 - accuracy: 0.7448 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7448 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4760 - accuracy: 0.7448 - val_loss: 0.5178 - val_accuracy: 0.7240\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7448 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7448 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4757 - accuracy: 0.7448 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4755 - accuracy: 0.7448 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4754 - accuracy: 0.7448 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7448 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 980us/step - loss: 0.4753 - accuracy: 0.7448 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7431 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7431 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7431 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7431 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4748 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7431 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.4744 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4738 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4737 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4734 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4734 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7413 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4731 - accuracy: 0.7413 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7413 - val_loss: 0.5177 - val_accuracy: 0.7240\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7413 - val_loss: 0.5177 - val_accuracy: 0.7240\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.7431 - val_loss: 0.5177 - val_accuracy: 0.7240\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.7431 - val_loss: 0.5177 - val_accuracy: 0.7240\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4727 - accuracy: 0.7431 - val_loss: 0.5177 - val_accuracy: 0.7188\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7448 - val_loss: 0.5177 - val_accuracy: 0.7188\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.7431 - val_loss: 0.5177 - val_accuracy: 0.7188\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7465 - val_loss: 0.5177 - val_accuracy: 0.7188\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7465 - val_loss: 0.5177 - val_accuracy: 0.7188\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7465 - val_loss: 0.5177 - val_accuracy: 0.7188\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7465 - val_loss: 0.5177 - val_accuracy: 0.7188\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4721 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4720 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.4720 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7135\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 959us/step - loss: 0.4719 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 954us/step - loss: 0.4717 - accuracy: 0.7465 - val_loss: 0.5178 - val_accuracy: 0.7188\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 958us/step - loss: 0.4714 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4713 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4710 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7465 - val_loss: 0.5179 - val_accuracy: 0.7188\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 968us/step - loss: 0.4709 - accuracy: 0.7465 - val_loss: 0.5180 - val_accuracy: 0.7188\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4708 - accuracy: 0.7465 - val_loss: 0.5180 - val_accuracy: 0.7188\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4708 - accuracy: 0.7465 - val_loss: 0.5180 - val_accuracy: 0.7188\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7465 - val_loss: 0.5180 - val_accuracy: 0.7188\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4707 - accuracy: 0.7483 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7483 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7483 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7483 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4705 - accuracy: 0.7500 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7500 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4705 - accuracy: 0.7483 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7465 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4703 - accuracy: 0.7483 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7465 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7483 - val_loss: 0.5180 - val_accuracy: 0.7135\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7483 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7483 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7483 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7483 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4700 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4699 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4698 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7483 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4697 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7483 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4695 - accuracy: 0.7483 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.7483 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7483 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4693 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.7135\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4692 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4691 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 957us/step - loss: 0.4691 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4689 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4689 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4688 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7135\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 947us/step - loss: 0.4686 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4684 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 961us/step - loss: 0.4684 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7483 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4681 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7135\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4681 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4680 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4679 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4679 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4678 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4678 - accuracy: 0.7517 - val_loss: 0.5184 - val_accuracy: 0.7135\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7135\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 937us/step - loss: 0.4677 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7135\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7135\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7188\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7500 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 941us/step - loss: 0.4676 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 953us/step - loss: 0.4675 - accuracy: 0.7535 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4674 - accuracy: 0.7535 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4673 - accuracy: 0.7535 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4672 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 990us/step - loss: 0.4672 - accuracy: 0.7535 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7535 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4671 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7535 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.4669 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4668 - accuracy: 0.7517 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4668 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4667 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7517 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4663 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 948us/step - loss: 0.4663 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4660 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7188\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 965us/step - loss: 0.4660 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7188\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 935us/step - loss: 0.4660 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7188\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 928us/step - loss: 0.4659 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7188\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.4659 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 946us/step - loss: 0.4658 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4658 - accuracy: 0.7535 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7569 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4657 - accuracy: 0.7569 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4657 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 937us/step - loss: 0.4657 - accuracy: 0.7517 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4656 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 979us/step - loss: 0.4655 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7569 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.7552 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7569 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4653 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4652 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 963us/step - loss: 0.4649 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4648 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7552 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4647 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.4646 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4645 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4640 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.4640 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4638 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7535 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7517 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7535 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7517 - val_loss: 0.5187 - val_accuracy: 0.7188\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.4627 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 960us/step - loss: 0.4625 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.7552 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 973us/step - loss: 0.4623 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7535 - val_loss: 0.5188 - val_accuracy: 0.7188\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7188\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 977us/step - loss: 0.4621 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7552 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4620 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7535 - val_loss: 0.5189 - val_accuracy: 0.7083\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7535 - val_loss: 0.5190 - val_accuracy: 0.7083\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7552 - val_loss: 0.5191 - val_accuracy: 0.7083\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7552 - val_loss: 0.5191 - val_accuracy: 0.7083\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7552 - val_loss: 0.5191 - val_accuracy: 0.7083\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7552 - val_loss: 0.5191 - val_accuracy: 0.7031\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7552 - val_loss: 0.5191 - val_accuracy: 0.7031\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7569 - val_loss: 0.5191 - val_accuracy: 0.7031\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7535 - val_loss: 0.5191 - val_accuracy: 0.7031\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7552 - val_loss: 0.5191 - val_accuracy: 0.7031\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4612 - accuracy: 0.7552 - val_loss: 0.5191 - val_accuracy: 0.7031\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7552 - val_loss: 0.5191 - val_accuracy: 0.7031\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7552 - val_loss: 0.5191 - val_accuracy: 0.7031\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 987us/step - loss: 0.4611 - accuracy: 0.7535 - val_loss: 0.5191 - val_accuracy: 0.7031\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7552 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7535 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7552 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7535 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7552 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7552 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7535 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7535 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 998us/step - loss: 0.4608 - accuracy: 0.7535 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7535 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7552 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7552 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7535 - val_loss: 0.5192 - val_accuracy: 0.6979\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7552 - val_loss: 0.5193 - val_accuracy: 0.6979\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7517 - val_loss: 0.5193 - val_accuracy: 0.6979\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7535 - val_loss: 0.5193 - val_accuracy: 0.6979\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7535 - val_loss: 0.5193 - val_accuracy: 0.6979\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7535 - val_loss: 0.5193 - val_accuracy: 0.6979\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7535 - val_loss: 0.5193 - val_accuracy: 0.6979\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7535 - val_loss: 0.5193 - val_accuracy: 0.6979\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4605 - accuracy: 0.7517 - val_loss: 0.5193 - val_accuracy: 0.6979\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7517 - val_loss: 0.5193 - val_accuracy: 0.6979\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7517 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7535 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7517 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7535 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7535 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4604 - accuracy: 0.7552 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7535 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7552 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7535 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7535 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.7517 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4602 - accuracy: 0.7517 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4601 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 977us/step - loss: 0.4600 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.7569 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 950us/step - loss: 0.4599 - accuracy: 0.7569 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4599 - accuracy: 0.7569 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7569 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7569 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7569 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7569 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 962us/step - loss: 0.4597 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 971us/step - loss: 0.4596 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4595 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7569 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7535 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7569 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 1000us/step - loss: 0.4588 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4587 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4586 - accuracy: 0.7535 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4585 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4584 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 932us/step - loss: 0.4583 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7535 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4578 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 943us/step - loss: 0.4577 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 930us/step - loss: 0.4576 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4575 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4573 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4572 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6927\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 938us/step - loss: 0.4568 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 975us/step - loss: 0.4567 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7552 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4564 - accuracy: 0.7552 - val_loss: 0.5201 - val_accuracy: 0.6927\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 917us/step - loss: 0.4563 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.4560 - accuracy: 0.7552 - val_loss: 0.5200 - val_accuracy: 0.6927\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7552 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7552 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7552 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7552 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7552 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7535 - val_loss: 0.5199 - val_accuracy: 0.6927\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7552 - val_loss: 0.5198 - val_accuracy: 0.6927\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4554 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.6927\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.6927\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7535 - val_loss: 0.5197 - val_accuracy: 0.6927\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.6927\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.6927\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.6927\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7552 - val_loss: 0.5197 - val_accuracy: 0.6927\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6927\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6927\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6927\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6927\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6927\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6927\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6927\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7552 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4548 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 963us/step - loss: 0.4546 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7552 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7552 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7569 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7552 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7552 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7569 - val_loss: 0.5194 - val_accuracy: 0.6979\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 976us/step - loss: 0.4539 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 977us/step - loss: 0.4535 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 967us/step - loss: 0.4533 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4532 - accuracy: 0.7569 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7552 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4528 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7535 - val_loss: 0.5195 - val_accuracy: 0.6979\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.4527 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7535 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4524 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4523 - accuracy: 0.7517 - val_loss: 0.5196 - val_accuracy: 0.6979\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 992us/step - loss: 0.4523 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7517 - val_loss: 0.5197 - val_accuracy: 0.6979\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 964us/step - loss: 0.4519 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7517 - val_loss: 0.5198 - val_accuracy: 0.6979\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4518 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6979\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 933us/step - loss: 0.4517 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6979\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6979\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6979\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4517 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6979\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6979\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6979\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6979\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6979\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.6979\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.6979\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.6979\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.6979\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.6979\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.6979\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.6979\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.6979\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.6979\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 982us/step - loss: 0.4514 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.6979\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.6979\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7517 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7517 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 993us/step - loss: 0.4514 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4513 - accuracy: 0.7517 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7517 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4513 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7517 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.4512 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4512 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7535 - val_loss: 0.5201 - val_accuracy: 0.6979\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4512 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 952us/step - loss: 0.4511 - accuracy: 0.7517 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 960us/step - loss: 0.4510 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7535 - val_loss: 0.5202 - val_accuracy: 0.6979\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4509 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.6979\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.6979\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.6979\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.6979\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 942us/step - loss: 0.4509 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.6979\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.6979\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.6979\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.6979\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.6979\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7535 - val_loss: 0.5203 - val_accuracy: 0.6979\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7535 - val_loss: 0.5204 - val_accuracy: 0.6979\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7535 - val_loss: 0.5204 - val_accuracy: 0.6979\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4507 - accuracy: 0.7517 - val_loss: 0.5204 - val_accuracy: 0.6979\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7535 - val_loss: 0.5204 - val_accuracy: 0.6979\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 965us/step - loss: 0.4507 - accuracy: 0.7535 - val_loss: 0.5204 - val_accuracy: 0.6979\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4507 - accuracy: 0.7535 - val_loss: 0.5204 - val_accuracy: 0.6979\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7535 - val_loss: 0.5204 - val_accuracy: 0.6979\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7535 - val_loss: 0.5204 - val_accuracy: 0.7031\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7535 - val_loss: 0.5204 - val_accuracy: 0.7031\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7552 - val_loss: 0.5204 - val_accuracy: 0.7031\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7517 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4505 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4504 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 991us/step - loss: 0.4504 - accuracy: 0.7535 - val_loss: 0.5205 - val_accuracy: 0.7031\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7517 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4503 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.7517 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 902us/step - loss: 0.4501 - accuracy: 0.7552 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7517 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7517 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7535 - val_loss: 0.5206 - val_accuracy: 0.7031\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 970us/step - loss: 0.4500 - accuracy: 0.7517 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7517 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7535 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7535 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7535 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 934us/step - loss: 0.4499 - accuracy: 0.7535 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4499 - accuracy: 0.7552 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7552 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7552 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 999us/step - loss: 0.4498 - accuracy: 0.7552 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7552 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.4498 - accuracy: 0.7552 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7552 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.7535 - val_loss: 0.5207 - val_accuracy: 0.7031\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7552 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7552 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7535 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7535 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7552 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7552 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7535 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7535 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4496 - accuracy: 0.7535 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7552 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7552 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7552 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7535 - val_loss: 0.5208 - val_accuracy: 0.7031\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 984us/step - loss: 0.4495 - accuracy: 0.7535 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7552 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7552 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7569 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7535 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7535 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7535 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7552 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7552 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7552 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7552 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7552 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7552 - val_loss: 0.5209 - val_accuracy: 0.7031\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4492 - accuracy: 0.7552 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7569 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7552 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7535 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7552 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7552 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7552 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7569 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 995us/step - loss: 0.4490 - accuracy: 0.7552 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4491 - accuracy: 0.7552 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7552 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7535 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7535 - val_loss: 0.5210 - val_accuracy: 0.7031\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4490 - accuracy: 0.7535 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7569 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7587 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7552 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7569 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7552 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7552 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7552 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7569 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7587 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7569 - val_loss: 0.5211 - val_accuracy: 0.7031\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7031\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7031\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7031\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7031\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 987us/step - loss: 0.4485 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4485 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 936us/step - loss: 0.4484 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7135\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7135\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7135\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.4483 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7135\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7135\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7135\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7135\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7135\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7135\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 945us/step - loss: 0.4482 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4482 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7604 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7587 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7569 - val_loss: 0.5212 - val_accuracy: 0.7083\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7569 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7569 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.7587 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7587 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7569 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7587 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7604 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7604 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7604 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7604 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 989us/step - loss: 0.4479 - accuracy: 0.7604 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4478 - accuracy: 0.7604 - val_loss: 0.5213 - val_accuracy: 0.7083\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7587 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7587 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.7587 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 983us/step - loss: 0.4476 - accuracy: 0.7587 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 994us/step - loss: 0.4475 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4474 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 954us/step - loss: 0.4474 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4470 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7587 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 974us/step - loss: 0.4468 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7083\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4462 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 966us/step - loss: 0.4462 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4460 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 972us/step - loss: 0.4459 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7083\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4458 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7135\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7135\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7135\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7135\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7135\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7135\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7135\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7135\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7639 - val_loss: 0.5214 - val_accuracy: 0.7135\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7135\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7622 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4455 - accuracy: 0.7656 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7604 - val_loss: 0.5214 - val_accuracy: 0.7188\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 978us/step - loss: 0.4455 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7604 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 996us/step - loss: 0.4452 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 997us/step - loss: 0.4451 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7188\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7622 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.7639 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 986us/step - loss: 0.4450 - accuracy: 0.7639 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7639 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7639 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.7639 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7639 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7639 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7656 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7656 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7656 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4447 - accuracy: 0.7656 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7656 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7656 - val_loss: 0.5216 - val_accuracy: 0.7188\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 942us/step - loss: 0.4446 - accuracy: 0.7656 - val_loss: 0.5216 - val_accuracy: 0.7188\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7639 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4445 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7188\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 988us/step - loss: 0.4444 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4443 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7622 - val_loss: 0.5218 - val_accuracy: 0.7188\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 955us/step - loss: 0.4439 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7622 - val_loss: 0.5219 - val_accuracy: 0.7188\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 956us/step - loss: 0.4437 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.7622 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7639 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7639 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7639 - val_loss: 0.5220 - val_accuracy: 0.7188\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7639 - val_loss: 0.5221 - val_accuracy: 0.7188\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7639 - val_loss: 0.5221 - val_accuracy: 0.7188\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7656 - val_loss: 0.5221 - val_accuracy: 0.7188\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7656 - val_loss: 0.5221 - val_accuracy: 0.7188\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7656 - val_loss: 0.5221 - val_accuracy: 0.7135\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.7656 - val_loss: 0.5221 - val_accuracy: 0.7135\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7656 - val_loss: 0.5221 - val_accuracy: 0.7135\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7656 - val_loss: 0.5221 - val_accuracy: 0.7135\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7656 - val_loss: 0.5221 - val_accuracy: 0.7135\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.7656 - val_loss: 0.5221 - val_accuracy: 0.7135\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 490us/step\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/carlospalominovidal/Library/CloudStorage/OneDrive-UniversidadPeruanadeCiencias/ESTUDIOS/Machine learning - big data/Machine learning ibm especialización/Codigo/05_Deep_Learning_and_Reinforcement_Learning/05d_LAB_Keras_Intro.ipynb Celda 39\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlospalominovidal/Library/CloudStorage/OneDrive-UniversidadPeruanadeCiencias/ESTUDIOS/Machine%20learning%20-%20big%20data/Machine%20learning%20ibm%20especializacio%CC%81n/Codigo/05_Deep_Learning_and_Reinforcement_Learning/05d_LAB_Keras_Intro.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred_prob_nn_2\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39margmax(y_pred_prob_nn_1,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlospalominovidal/Library/CloudStorage/OneDrive-UniversidadPeruanadeCiencias/ESTUDIOS/Machine%20learning%20-%20big%20data/Machine%20learning%20ibm%20especializacio%CC%81n/Codigo/05_Deep_Learning_and_Reinforcement_Learning/05d_LAB_Keras_Intro.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/carlospalominovidal/Library/CloudStorage/OneDrive-UniversidadPeruanadeCiencias/ESTUDIOS/Machine%20learning%20-%20big%20data/Machine%20learning%20ibm%20especializacio%CC%81n/Codigo/05_Deep_Learning_and_Reinforcement_Learning/05d_LAB_Keras_Intro.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39maccuracy is \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(accuracy_score(y_test,y_pred_class_nn_2)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlospalominovidal/Library/CloudStorage/OneDrive-UniversidadPeruanadeCiencias/ESTUDIOS/Machine%20learning%20-%20big%20data/Machine%20learning%20ibm%20especializacio%CC%81n/Codigo/05_Deep_Learning_and_Reinforcement_Learning/05d_LAB_Keras_Intro.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mroc-auc is \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(roc_auc_score(y_test,y_pred_prob_nn_2)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/carlospalominovidal/Library/CloudStorage/OneDrive-UniversidadPeruanadeCiencias/ESTUDIOS/Machine%20learning%20-%20big%20data/Machine%20learning%20ibm%20especializacio%CC%81n/Codigo/05_Deep_Learning_and_Reinforcement_Learning/05d_LAB_Keras_Intro.ipynb#X53sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plot_roc(y_test, y_pred_prob_nn_2, \u001b[39m'\u001b[39m\u001b[39mNN-2\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "y_pred_class_nn_2 = model_1.predict(X_test_norm)\n",
    "y_pred_prob_nn_2=np.argmax(y_pred_prob_nn_1,axis=1)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
